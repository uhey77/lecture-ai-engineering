{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSpnWBP5ELSI"
      },
      "source": [
        "# 実践演習 Day 1：streamlitとFastAPIのデモ\n",
        "このノートブックでは以下の内容を学習します。\n",
        "\n",
        "- 必要なライブラリのインストールと環境設定\n",
        "- Hugging Faceからモデルを用いたStreamlitのデモアプリ\n",
        "- FastAPIとngrokを使用したAPIの公開方法\n",
        "\n",
        "演習を始める前に、HuggingFaceとngrokのアカウントを作成し、\n",
        "それぞれのAPIトークンを取得する必要があります。\n",
        "\n",
        "\n",
        "演習の時間では、以下の3つのディレクトリを順に説明します。\n",
        "\n",
        "1. 01_streamlit_UI\n",
        "2. 02_streamlit_app\n",
        "3. 03_FastAPI\n",
        "\n",
        "2つ目や3つ目からでも始められる様にノートブックを作成しています。\n",
        "\n",
        "復習の際にもこのノートブックを役立てていただければと思います。\n",
        "\n",
        "### 注意事項\n",
        "「02_streamlit_app」と「03_FastAPI」では、GPUを使用します。\n",
        "\n",
        "これらを実行する際は、Google Colab画面上のメニューから「編集」→ 「ノートブックの設定」\n",
        "\n",
        "「ハードウェアアクセラレーター」の項目の中から、「T4 GPU」を選択してください。\n",
        "\n",
        "このノートブックのデフォルトは「CPU」になっています。\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhtHkJOgELSL"
      },
      "source": [
        "# 環境変数の設定（1~3共有）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-FjBp4MMQHM"
      },
      "source": [
        "GitHubから演習用のコードをCloneします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIXMavdDEP8U",
        "outputId": "1fafed51-a8f6-4147-bb25-43e65ac3df73"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/matsuolab/lecture-ai-engineering.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC8n7yZ_vs1K"
      },
      "source": [
        "必要なAPIトークンを.envに設定します。\n",
        "\n",
        "「lecture-ai-engineering/day1」の配下に、「.env_template」ファイルが存在しています。\n",
        "\n",
        "隠しファイルのため表示されていない場合は、画面左側のある、目のアイコンの「隠しファイルの表示」ボタンを押してください。\n",
        "\n",
        "「.env_template」のファイル名を「.env」に変更します。「.env」ファイルを開くと、以下のような中身になっています。\n",
        "\n",
        "\n",
        "```\n",
        "HUGGINGFACE_TOKEN=\"hf-********\"\n",
        "NGROK_TOKEN=\"********\"\n",
        "```\n",
        "ダブルクオーテーションで囲まれた文字列をHuggingfaceのアクセストークンと、ngrokの認証トークンで書き変えてください。\n",
        "\n",
        "それぞれのアカウントが作成済みであれば、以下のURLからそれぞれのトークンを取得できます。\n",
        "\n",
        "- Huggingfaceのアクセストークン\n",
        "https://huggingface.co/docs/hub/security-tokens\n",
        "\n",
        "- ngrokの認証トークン\n",
        "https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "書き換えたら、「.env」ファイルをローカルのPCにダウンロードしてください。\n",
        "\n",
        "「01_streamlit_UI」から「02_streamlit_app」へ進む際に、CPUからGPUの利用に切り替えるため、セッションが一度切れてしまいます。\n",
        "\n",
        "その際に、トークンを設定した「.env」ファイルは再作成することになるので、その手間を減らすために「.env」ファイルをダウンロードしておくと良いです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py1BFS5RqcSS"
      },
      "source": [
        "「.env」ファイルを読み込み、環境変数として設定します。次のセルを実行し、最終的に「True」が表示されていればうまく読み込めています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvEowFfg5lrq",
        "outputId": "baa8488d-aa6f-45b6-c7eb-0f06bd6a8165"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# !pip install python-dotenv\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# %cd /content/lecture-ai-engineering/day1\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTE7nUlM160Q"
      },
      "source": [
        "環境変数を一時的に保存しておくコード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BLkrs1sc2CTT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def save_env_backup():\n",
        "        env_backup = {\n",
        "                \"HUGGINGFACE_TOKEN\": os.environ.get(\"HUGGINGFACE_TOKEN\"),\n",
        "                \"NGROK_TOKEN\": os.environ.get(\"NGROK_TOKEN\")\n",
        "            }\n",
        "        with open('/content/env_backup.json', 'w') as f:\n",
        "              json.dump(env_backup, f)\n",
        "        print(\"環境変数のバックアップを作成しました。セッションが切断された場合は restore_env_backup() を実行してください。\")\n",
        "\n",
        "        # 環境変数を復元する関数\n",
        "        def restore_env_backup():\n",
        "            try:\n",
        "                with open('/content/env_backup.json', 'r') as f:\n",
        "                    env_backup = json.load(f)\n",
        "\n",
        "                # 環境変数を復元\n",
        "                for key, value in env_backup.items():\n",
        "                    os.environ[key] = value\n",
        "\n",
        "                # .env ファイルを再作成\\n\",\n",
        "                with open('/content/lecture-ai-engineering/day1/.env', 'w') as f:\n",
        "                    for key, value in env_backup.items():\n",
        "                        f.write(f\"{key}={value}\")\n",
        "\n",
        "                print(\"環境変数を復元しました。\")\n",
        "                return True\n",
        "            except FileNotFoundError:\n",
        "                print(\"バックアップファイルが見つかりません。環境変数を手動で設定してください。\")\n",
        "                return False\n",
        "\n",
        "        # バックアップを作成\n",
        "        save_env_backup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os0Yk6gaELSM"
      },
      "source": [
        "# 01_streamlit_UI\n",
        "\n",
        "ディレクトリ「01_streamlit_UI」に移動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S28XgOm0ELSM",
        "outputId": "113a90ce-059f-4644-cd6e-f361dd533d3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/lecture-ai-engineering/day1/01_streamlit_UI\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/01_streamlit_UI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVp-aEIkELSM"
      },
      "source": [
        "必要なライブラリをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nBe41LFiELSN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# 追加ライブラリのインストール\n",
        "!pip install streamlit-option-menu streamlit-authenticator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw3EGhkd4MZV"
      },
      "source": [
        "**新しい UI コンポーネントを追加**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6aCDSi04WwI",
        "outputId": "97e9e1f5-e609-4134-f0a6-47e6ddc2e3c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting custom_ui.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile custom_ui.py\n",
        "\"\"\"\n",
        "custom_ui.py\n",
        "-----------------\n",
        "Streamlit 用のサイドバー＆カスタムページ部品。\n",
        "• メニュー選択・テーマ切替\n",
        "• ホームページのカードとプログレスバー\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "import time\n",
        "import streamlit as st\n",
        "from streamlit_option_menu import option_menu\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# サイドバー\n",
        "# ----------------------------------------------------------------------\n",
        "_MENU_ITEMS = [\"ホーム\", \"基本要素\", \"レイアウト\", \"入力要素\", \"テーマ設定\"]\n",
        "_ICONS = [\"house\", \"list-task\", \"columns\", \"input-cursor\", \"palette\"]\n",
        "\n",
        "\n",
        "def _apply_dark_theme(enable_dark: bool) -> None:\n",
        "    \"\"\"ダークテーマを CSS で適用／解除する。\"\"\"\n",
        "    if enable_dark:\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "            <style>\n",
        "            .main {background-color: #0E1117; color: #FFFFFF;}\n",
        "            .sidebar .sidebar-content {background-color: #262730; color: #FFFFFF;}\n",
        "            </style>\n",
        "            \"\"\",\n",
        "            unsafe_allow_html=True,\n",
        "        )\n",
        "\n",
        "\n",
        "def create_sidebar() -> str:\n",
        "    \"\"\"\n",
        "    カスタムサイドバーを生成し、選択されたメニューを返す。\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        現在選択中のページ名。\n",
        "    \"\"\"\n",
        "    with st.sidebar:\n",
        "        selected = option_menu(\n",
        "            menu_title=\"メインメニュー\",\n",
        "            options=_MENU_ITEMS,\n",
        "            icons=_ICONS,\n",
        "            menu_icon=\"cast\",\n",
        "            default_index=0,\n",
        "        )\n",
        "\n",
        "        # テーマ切替スイッチ\n",
        "        if \"light_mode\" not in st.session_state:\n",
        "            st.session_state.light_mode = True\n",
        "\n",
        "        if st.button(\"🌓 テーマ切替\"):\n",
        "            st.session_state.light_mode = not st.session_state.light_mode\n",
        "\n",
        "    # サイドバー外でテーマ適用（CSS は 1 度のみ挿入）\n",
        "    _apply_dark_theme(not st.session_state.light_mode)\n",
        "\n",
        "    return selected\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 共通ユーティリティ\n",
        "# ----------------------------------------------------------------------\n",
        "def page_hourglass() -> None:\n",
        "    \"\"\"デモ用のプログレスバーを表示するページ。\"\"\"\n",
        "    st.subheader(\"改善されたプログレス表示\")\n",
        "    progress_text = \"処理中です。しばらくお待ちください...\"\n",
        "    bar = st.progress(0, text=progress_text)\n",
        "    placeholder = st.empty()\n",
        "\n",
        "    for percent in range(100):\n",
        "        time.sleep(0.02)\n",
        "        bar.progress(percent + 1, text=f\"{progress_text} ({percent + 1}%)\")\n",
        "        if percent % 10 == 0:\n",
        "            placeholder.info(f\"Step {percent // 10 + 1}/10 完了\")\n",
        "\n",
        "    bar.empty()\n",
        "    placeholder.empty()\n",
        "    st.success(\"処理が完了しました！\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# ページ切替ハブ\n",
        "# ----------------------------------------------------------------------\n",
        "def show_custom_pages(selected: str) -> str:\n",
        "    \"\"\"\n",
        "    選択されたページに対応するコンテンツを描画する。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    selected : str\n",
        "        create_sidebar から返されたページ名。\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        同じ値を返すだけ（呼び出し元での再利用用）。\n",
        "    \"\"\"\n",
        "    if selected == \"ホーム\":\n",
        "        _render_home()\n",
        "\n",
        "    # そのほかのページは app.py で処理\n",
        "    return selected\n",
        "\n",
        "\n",
        "def _render_home() -> None:\n",
        "    \"\"\"ホームページを描画。\"\"\"\n",
        "    st.title(\"Streamlit UIデモ（改善版）\")\n",
        "    st.write(\n",
        "        \"\"\"\n",
        "        このデモアプリは、Streamlit の基本的な UI 要素を紹介するものです。\n",
        "        サイドバーから異なるセクションを選択して、さまざまなコンポーネントをお試しください。\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # カード風に 3 カラムで機能案内\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    with col1:\n",
        "        st.info(\"**基本要素**\\n\\nテキスト、ヘッダー、メディアなど\")\n",
        "    with col2:\n",
        "        st.success(\"**レイアウト**\\n\\n列、タブ、エキスパンダーなど\")\n",
        "    with col3:\n",
        "        st.warning(\"**入力要素**\\n\\nボタン、スライダー、テキスト入力など\")\n",
        "\n",
        "    # プログレスバーのデモ起動\n",
        "    if st.button(\"プログレスバーデモを表示\"):\n",
        "        page_hourglass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyw6VHaTELSN"
      },
      "source": [
        "ngrokのトークンを使用して、認証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYw1q0iXELSN",
        "outputId": "393d9179-e244-4452-bfde-50956165de5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x2rBm74meW9"
      },
      "source": [
        "**app.pyの書き換え**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqPQcRxLmikL",
        "outputId": "b02a3da3-ceeb-465d-c8cd-56b833379189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\"\"\"Streamlit UI Demo — cleaned & refactored\n",
        "------------------------------------------------\n",
        "A single‑file demo app showcasing basic Streamlit components.\n",
        "Split into small render_* functions for readability.\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "import io\n",
        "from datetime import date as dt_date\n",
        "from typing import Callable, Dict\n",
        "\n",
        "import altair as alt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "\n",
        "from custom_ui import create_sidebar, show_custom_pages\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# ページ共通ユーティリティ\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "def random_df(rows: int = 20, cols: int = 3, colnames: list[str] | None = None) -> pd.DataFrame:\n",
        "    \"\"\"ランダム DataFrame を生成。\"\"\"\n",
        "    if colnames is None:\n",
        "        colnames = list(\"ABC\")[:cols]\n",
        "    return pd.DataFrame(np.random.randn(rows, cols), columns=colnames)\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# 個別ページ描画関数\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "def render_basic() -> None:\n",
        "    \"\"\"基本 UI 要素ページ\"\"\"\n",
        "    st.title(\"基本要素\")\n",
        "\n",
        "    # --- テキスト類 ---\n",
        "    st.header(\"テキスト要素\")\n",
        "    st.text(\"これは通常のテキストです。\")\n",
        "    st.markdown(\"**これはマークダウンテキストです。** *イタリック* や `コード` も使えます。\")\n",
        "    st.info(\"これは情報メッセージです。\")\n",
        "    st.warning(\"これは警告メッセージです。\")\n",
        "    st.error(\"これはエラーメッセージです。\")\n",
        "    st.success(\"これは成功メッセージです。\")\n",
        "\n",
        "    # --- メディア要素 ---\n",
        "    st.header(\"メディア要素\")\n",
        "    tab_chart, tab_df, tab_img = st.tabs([\"📈 チャート\", \"🗃 DataFrame\", \"🖼 画像\"])\n",
        "\n",
        "    with tab_chart:\n",
        "        st.subheader(\"折れ線グラフ\")\n",
        "        chart_data = random_df()\n",
        "        st.line_chart(chart_data)\n",
        "\n",
        "        st.subheader(\"Altair チャート\")\n",
        "        c = (\n",
        "            alt.Chart(chart_data.reset_index())\n",
        "            .mark_circle()\n",
        "            .encode(x=\"index\", y=\"A\", size=\"B\", color=\"C\", tooltip=[\"A\", \"B\", \"C\"])\n",
        "            .interactive()\n",
        "        )\n",
        "        st.altair_chart(c, use_container_width=True)\n",
        "\n",
        "    with tab_df:\n",
        "        st.subheader(\"DataFrame の表示\")\n",
        "        df = pd.DataFrame({\n",
        "            \"名前\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
        "            \"年齢\": [24, 42, 18, 31],\n",
        "            \"都市\": [\"東京\", \"大阪\", \"京都\", \"名古屋\"],\n",
        "        })\n",
        "        st.dataframe(df, use_container_width=True)\n",
        "        st.download_button(\"CSVとしてダウンロード\", df.to_csv(index=False, encoding=\"utf-8-sig\"), \"sample_data.csv\", \"text/csv\")\n",
        "\n",
        "    with tab_img:\n",
        "        st.subheader(\"動的に生成した画像\")\n",
        "        fig, ax = plt.subplots()\n",
        "        x = np.linspace(0, 10, 100)\n",
        "        ax.plot(x, np.sin(x))\n",
        "        ax.set_title(\"サイン波\")\n",
        "        ax.grid(True)\n",
        "        buf = io.BytesIO()\n",
        "        fig.savefig(buf, format=\"png\")\n",
        "        st.image(buf.getvalue(), caption=\"動的に生成されたサイン波\", use_column_width=True)\n",
        "\n",
        "\n",
        "def render_layout() -> None:\n",
        "    \"\"\"レイアウト要素ページ\"\"\"\n",
        "    st.title(\"レイアウト要素\")\n",
        "\n",
        "    st.header(\"カラムレイアウト\")\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    with col1:\n",
        "        st.subheader(\"カラム1\")\n",
        "        st.image(\"https://via.placeholder.com/150\", caption=\"プレースホルダー画像\")\n",
        "    with col2:\n",
        "        st.subheader(\"カラム2\")\n",
        "        st.metric(\"温度\", \"28°C\", \"1.2°C\")\n",
        "    with col3:\n",
        "        st.subheader(\"カラム3\")\n",
        "        st.metric(\"湿度\", \"65%\", \"-4%\", delta_color=\"inverse\")\n",
        "\n",
        "    st.header(\"エキスパンダー\")\n",
        "    with st.expander(\"詳細を表示\"):\n",
        "        st.write(\"\"\"\n",
        "            エキスパンダーを使用すると、長いコンテンツを折りたたむことができます。\n",
        "            ユーザーが必要なときに展開できるため、画面スペースを節約できます。\n",
        "        \"\"\")\n",
        "        st.image(\"https://via.placeholder.com/400x200\", caption=\"大きなプレースホルダー画像\")\n",
        "\n",
        "    st.header(\"タブ\")\n",
        "    tab1, tab2, tab3 = st.tabs([\"Tab 1\", \"Tab 2\", \"Tab 3\"])\n",
        "    with tab1:\n",
        "        st.bar_chart(random_df(10, 3, [\"X\", \"Y\", \"Z\"]))\n",
        "    with tab2:\n",
        "        st.line_chart(pd.DataFrame(np.sin(np.linspace(0, 10, 100))))\n",
        "    with tab3:\n",
        "        st.area_chart(random_df(10).cumsum())\n",
        "\n",
        "\n",
        "def render_inputs() -> None:\n",
        "    \"\"\"入力要素ページ\"\"\"\n",
        "    st.title(\"入力要素\")\n",
        "\n",
        "    # --- ボタン ---\n",
        "    st.header(\"ボタン\")\n",
        "    if st.button(\"クリックしてください\"):\n",
        "        st.success(\"ボタンがクリックされました！\")\n",
        "\n",
        "    # --- チェックボックス ---\n",
        "    st.header(\"チェックボックス\")\n",
        "    if st.checkbox(\"チェックボックスを表示\"):\n",
        "        st.write(\"チェックボックスがオンになっています。\")\n",
        "\n",
        "    # --- ラジオボタン ---\n",
        "    st.header(\"ラジオボタン\")\n",
        "    genre = st.radio(\"好きな音楽ジャンルは？\", (\"ロック\", \"ポップ\", \"ジャズ\", \"クラシック\"))\n",
        "    if genre:\n",
        "        st.write(f\"あなたは {genre} を選択しました。\")\n",
        "\n",
        "    # --- セレクトボックス ---\n",
        "    st.header(\"セレクトボックス\")\n",
        "    color = st.selectbox(\"好きな色は？\", (\"赤\", \"青\", \"緑\", \"黄色\"))\n",
        "    st.write(f\"あなたが選んだのは: {color}\")\n",
        "\n",
        "    # --- マルチセレクト ---\n",
        "    st.header(\"マルチセレクト\")\n",
        "    fruits = st.multiselect(\n",
        "        \"好きな果物は？\",\n",
        "        [\"りんご\", \"バナナ\", \"オレンジ\", \"ぶどう\", \"いちご\"],\n",
        "        default=[\"りんご\", \"バナナ\"],\n",
        "    )\n",
        "    st.write(\"あなたが選んだのは: \" + \", \".join(fruits))\n",
        "\n",
        "    # --- スライダー ---\n",
        "    st.header(\"スライダー\")\n",
        "    age = st.slider(\"あなたの年齢は？\", 0, 100, 25)\n",
        "    st.write(f\"あなたの年齢: {age}歳\")\n",
        "\n",
        "    # --- 範囲スライダー ---\n",
        "    values = st.slider(\"値の範囲を選択:\", 0.0, 100.0, (25.0, 75.0))\n",
        "    st.write(f\"選択された範囲: {values[0]} から {values[1]}\")\n",
        "\n",
        "    # --- 日付入力 ---\n",
        "    st.header(\"日付入力\")\n",
        "    birth = st.date_input(\"生年月日を選択してください\", dt_date(2000, 1, 1))\n",
        "    st.write(f\"あなたの生年月日: {birth}\")\n",
        "\n",
        "    # --- ファイルアップローダー ---\n",
        "    st.header(\"ファイルアップローダー\")\n",
        "    uploaded = st.file_uploader(\"ファイルを選択してください\", type=[\"csv\", \"xlsx\", \"txt\", \"jpg\", \"png\"])\n",
        "    if uploaded is not None:\n",
        "        st.write(f\"ファイル名: {uploaded.name} — {uploaded.size} bytes\")\n",
        "        if uploaded.type.startswith(\"image\"):\n",
        "            st.image(uploaded, caption=\"アップロードされた画像\", use_column_width=True)\n",
        "        elif uploaded.type == \"text/plain\":\n",
        "            string_data = io.StringIO(uploaded.getvalue().decode()).read()\n",
        "            st.text_area(\"ファイルの内容\", string_data, height=200)\n",
        "        elif uploaded.type == \"text/csv\":\n",
        "            st.dataframe(pd.read_csv(uploaded), use_container_width=True)\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# テーマ設定ページは custom_ui.py 内の CSS で制御\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# ページ設定 & ルーティング\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "def main() -> None:\n",
        "    st.set_page_config(\n",
        "        page_title=\"Streamlit UIデモ（改善版）\",\n",
        "        page_icon=\"🧊\",\n",
        "        layout=\"wide\",\n",
        "        initial_sidebar_state=\"expanded\",\n",
        "    )\n",
        "\n",
        "    selected = create_sidebar()\n",
        "    selected = show_custom_pages(selected)  # ホームなど custom_ui 側\n",
        "\n",
        "    page_table: Dict[str, Callable[[], None]] = {\n",
        "        \"基本要素\": render_basic,\n",
        "        \"レイアウト\": render_layout,\n",
        "        \"入力要素\": render_inputs,\n",
        "    }\n",
        "\n",
        "    if selected in page_table:\n",
        "        page_table[selected]()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RssTcD_IELSN"
      },
      "source": [
        "アプリを起動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-E7ucR6ELSN",
        "outputId": "9621cd0b-919d-4d0d-92f0-6d4d50332606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "公開URL: https://f89e-34-125-210-255.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.210.255:8501\u001b[0m\n",
            "\u001b[0m\n",
            "/content/lecture-ai-engineering/day1/01_streamlit_UI/app.py:84: UserWarning: Glyph 12469 (\\N{KATAKANA LETTER SA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(buf, format=\"png\")\n",
            "/content/lecture-ai-engineering/day1/01_streamlit_UI/app.py:84: UserWarning: Glyph 12452 (\\N{KATAKANA LETTER I}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(buf, format=\"png\")\n",
            "/content/lecture-ai-engineering/day1/01_streamlit_UI/app.py:84: UserWarning: Glyph 12531 (\\N{KATAKANA LETTER N}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(buf, format=\"png\")\n",
            "/content/lecture-ai-engineering/day1/01_streamlit_UI/app.py:84: UserWarning: Glyph 27874 (\\N{CJK UNIFIED IDEOGRAPH-6CE2}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(buf, format=\"png\")\n",
            "2025-04-21 05:45:37.838 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"公開URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbYyXVFjELSN"
      },
      "source": [
        "公開URLの後に記載されているURLにブラウザでアクセスすると、streamlitのUIが表示されます。\n",
        "\n",
        "app.pyのコメントアウトされている箇所を編集することで、UIがどの様に変化するか確認してみましょう。\n",
        "\n",
        "streamlitの公式ページには、ギャラリーページがあります。\n",
        "\n",
        "streamlitを使うとpythonという一つの言語であっても、様々なUIを実現できることがわかると思います。\n",
        "\n",
        "https://streamlit.io/gallery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmtP5GLOELSN"
      },
      "source": [
        "後片付けとして、使う必要のないngrokのトンネルを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "8Ek9QgahELSO"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-T8tFpyELSO"
      },
      "source": [
        "# 02_streamlit_app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqogFQKnELSO"
      },
      "source": [
        "\n",
        "ディレクトリ「02_streamlit_app」に移動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeEjlJ7uELSO",
        "outputId": "5aa30922-ceef-4b57-eb8a-2379a0cf0e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/lecture-ai-engineering/day1/02_streamlit_app\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/02_streamlit_app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XUH2AstELSO"
      },
      "source": [
        "必要なライブラリをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "mDqvI4V3ELSO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO31umGZELSO"
      },
      "source": [
        "ngrokとhuggigfaceのトークンを使用して、認証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPxTiEWQELSO",
        "outputId": "b5099379-14d1-4b42-d6cd-208898c564d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "The token `AIE_2` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `AIE_2`\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz4WrELLELSP"
      },
      "source": [
        "stramlitでHuggingfaceのトークン情報を扱うために、streamlit用の設定ファイル（.streamlit）を作成し、トークンの情報を格納します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "W184-a7qFP0W"
      },
      "outputs": [],
      "source": [
        "# .streamlit/secrets.toml ファイルを作成\n",
        "import os\n",
        "import toml\n",
        "\n",
        "# 設定ファイルのディレクトリ確保\n",
        "os.makedirs('.streamlit', exist_ok=True)\n",
        "\n",
        "# 環境変数から取得したトークンを設定ファイルに書き込む\n",
        "secrets = {\n",
        "    \"huggingface\": {\n",
        "        \"token\": os.environ.get(\"HUGGINGFACE_TOKEN\", \"\")\n",
        "    }\n",
        "}\n",
        "\n",
        "# 設定ファイルを書き込む\n",
        "with open('.streamlit/secrets.toml', 'w') as f:\n",
        "    toml.dump(secrets, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK0vI_xKELSP"
      },
      "source": [
        "アプリを起動します。\n",
        "\n",
        "02_streamlit_appでは、Huggingfaceからモデルをダウンロードするため、初回起動には2分程度時間がかかります。\n",
        "\n",
        "この待ち時間を利用して、app.pyのコードを確認してみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewbmHUlVEvy8"
      },
      "source": [
        "**config.py の書き換え**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLhul3GQE0Bu",
        "outputId": "63b2e244-9072-40e7-8ebb-df823336ba20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile config.py\n",
        "# モデル設定\n",
        "DATABASE_FILE = \"chat_history.db\"\n",
        "MODEL_NAME = \"meta-llama/Llama-3-8B-Japanese\"\n",
        "\n",
        "# UI設定\n",
        "MAX_HISTORY_ITEMS = 10\n",
        "THEME_COLOR = \"#FF4B4B\"\n",
        "ENABLE_DARK_MODE = True\n",
        "ENABLE_CACHING = True  # 追加：キャッシング機能の有効化\n",
        "STREAM_OUTPUT = False  # ストリーミング出力を無効化\n",
        "\n",
        "# 評価指標設定\n",
        "METRICS = [\n",
        "    \"bleu_score\",\n",
        "    \"cosine_similarity\",\n",
        "    \"sentiment_score\",\n",
        "    \"response_time\",\n",
        "    \"token_generation_speed\",\n",
        "    \"perplexity\"\n",
        "]\n",
        "\n",
        "# 追加機能設定\n",
        "ENABLE_CHAT_EXPORT = True\n",
        "ENABLE_ERROR_LOGGING = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhaRy8Bt6f4h"
      },
      "source": [
        "**metrics.py の書き換え**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBCnjqZ26ktb",
        "outputId": "74cc3d51-f1ec-4ce5-8a9e-496f679f4fe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting metrics.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile metrics.py\n",
        "import time\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "import math\n",
        "import re\n",
        "\n",
        "# 必要なNLTKデータのダウンロード\n",
        "try:\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    print(\"NLTK loaded successfully.\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "class MetricsCalculator:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "\n",
        "    def calculate_bleu_score(self, reference, candidate):\n",
        "        \"\"\"BLEUスコアを計算 (0-1, 高いほど良い)\"\"\"\n",
        "        reference_tokens = nltk.word_tokenize(reference.lower())\n",
        "        candidate_tokens = nltk.word_tokenize(candidate.lower())\n",
        "        return sentence_bleu([reference_tokens], candidate_tokens)\n",
        "\n",
        "    def calculate_cosine_similarity(self, text1, text2):\n",
        "        \"\"\"コサイン類似度を計算 (0-1, 高いほど似ている)\"\"\"\n",
        "        try:\n",
        "            tfidf_matrix = self.vectorizer.fit_transform([text1, text2])\n",
        "            return cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    def calculate_sentiment_score(self, text):\n",
        "        \"\"\"感情分析スコアを計算 (-1: 非常にネガティブ, 1: 非常にポジティブ)\"\"\"\n",
        "        sentiment = TextBlob(text).sentiment.polarity\n",
        "        return sentiment\n",
        "\n",
        "    def calculate_sentiment_metrics(self, text):\n",
        "        \"\"\"詳細な感情分析メトリクスを計算\"\"\"\n",
        "        sentiment = TextBlob(text).sentiment\n",
        "\n",
        "        return {\n",
        "            \"polarity\": sentiment.polarity,  # -1.0 to 1.0\n",
        "            \"subjectivity\": sentiment.subjectivity,  # 0.0 to 1.0\n",
        "            \"vader_compound\": sentiment.polarity,\n",
        "            \"vader_negative\": max(0, -sentiment.polarity),\n",
        "            \"vader_neutral\": 1.0 - abs(sentiment.polarity),\n",
        "            \"vader_positive\": max(0, sentiment.polarity)\n",
        "        }\n",
        "\n",
        "    def calculate_perplexity(self, text, n=3):\n",
        "        \"\"\"単純なN-gramモデルに基づくテキストの複雑さ推定（低いほど自然）\"\"\"\n",
        "        tokens = nltk.word_tokenize(text.lower())\n",
        "        if len(tokens) < n:\n",
        "            return float('inf')  # テキストが短すぎる場合\n",
        "\n",
        "        # N-gramカウント\n",
        "        ngrams = {}\n",
        "        for i in range(len(tokens) - n + 1):\n",
        "            gram = ' '.join(tokens[i:i+n-1])\n",
        "            next_token = tokens[i+n-1]\n",
        "\n",
        "            if gram not in ngrams:\n",
        "                ngrams[gram] = {}\n",
        "\n",
        "            if next_token not in ngrams[gram]:\n",
        "                ngrams[gram][next_token] = 0\n",
        "\n",
        "            ngrams[gram][next_token] += 1\n",
        "\n",
        "        # パープレキシティ計算\n",
        "        log_prob = 0.0\n",
        "        for i in range(len(tokens) - n + 1):\n",
        "            gram = ' '.join(tokens[i:i+n-1])\n",
        "            next_token = tokens[i+n-1]\n",
        "\n",
        "            if gram in ngrams and next_token in ngrams[gram]:\n",
        "                total = sum(ngrams[gram].values())\n",
        "                prob = ngrams[gram][next_token] / total\n",
        "                log_prob += math.log2(prob)\n",
        "            else:\n",
        "                log_prob += math.log2(1e-10)  # スムージング\n",
        "\n",
        "        perplexity = 2 ** (-log_prob / (len(tokens) - n + 1))\n",
        "        return perplexity\n",
        "\n",
        "    def calculate_response_time(self, start_time):\n",
        "        \"\"\"応答時間を計算（秒単位）\"\"\"\n",
        "        return time.time() - start_time\n",
        "\n",
        "    def calculate_token_generation_speed(self, text, generation_time):\n",
        "        \"\"\"トークン生成速度を計算（トークン/秒）\"\"\"\n",
        "        if generation_time <= 0:\n",
        "            return 0\n",
        "        # 簡易的なトークン数推定（実際にはモデルのトークナイザーによって異なる）\n",
        "        token_count = len(re.findall(r'\\w+|[^\\w\\s]', text))\n",
        "        return token_count / generation_time\n",
        "\n",
        "    def calculate_all_metrics(self, reference, candidate, generation_time):\n",
        "        \"\"\"すべての評価指標を計算\"\"\"\n",
        "        metrics = {\n",
        "            \"bleu_score\": self.calculate_bleu_score(reference, candidate),\n",
        "            \"cosine_similarity\": self.calculate_cosine_similarity(reference, candidate),\n",
        "            \"sentiment\": self.calculate_sentiment_metrics(candidate),\n",
        "            \"response_time\": generation_time,\n",
        "            \"token_generation_speed\": self.calculate_token_generation_speed(candidate, generation_time),\n",
        "            \"perplexity\": self.calculate_perplexity(candidate)\n",
        "        }\n",
        "        return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJahIGtm6crr"
      },
      "source": [
        "**llm.pyの書き換え**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APfi3UtA6HcZ",
        "outputId": "c5b9a581-f5b8-4385-b35c-1b8ab7e17121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting llm.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile llm.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "import time\n",
        "from config import MODEL_NAME, STREAM_OUTPUT, ENABLE_CACHING\n",
        "\n",
        "class LLMGenerator:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.load_model()\n",
        "\n",
        "    @st.cache_resource\n",
        "    def load_model_cached(_self):\n",
        "        \"\"\"モデルをロードしてキャッシュする\"\"\"\n",
        "        print(f\"モデル {MODEL_NAME} をロード中...\")\n",
        "\n",
        "        # 量子化設定\n",
        "        quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_compute_dtype=torch.float16\n",
        "        )\n",
        "\n",
        "        # トークナイザーとモデルのロード\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "        # モデルのロード（4bit量子化）\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            MODEL_NAME,\n",
        "            quantization_config=quantization_config,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.float16\n",
        "        )\n",
        "\n",
        "        return model, tokenizer\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"モデルのロード処理（キャッシュが有効な場合はキャッシュを使用）\"\"\"\n",
        "        if ENABLE_CACHING:\n",
        "            self.model, self.tokenizer = self.load_model_cached()\n",
        "        else:\n",
        "            print(f\"モデル {MODEL_NAME} をロード中...\")\n",
        "\n",
        "            # 量子化設定\n",
        "            quantization_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_compute_dtype=torch.float16\n",
        "            )\n",
        "\n",
        "            # トークナイザーとモデルのロード\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "            # モデルのロード（4bit量子化）\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                MODEL_NAME,\n",
        "                quantization_config=quantization_config,\n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.float16\n",
        "            )\n",
        "\n",
        "    def generate_text(self, prompt, max_length=512, temperature=0.7, stream_handler=None):\n",
        "        \"\"\"テキスト生成（シンプル版）\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # プロンプトのフォーマット\n",
        "            if \"meta-llama\" in MODEL_NAME.lower():\n",
        "                formatted_prompt = f\"<human>: {prompt}\\n<assistant>: \"\n",
        "            else:\n",
        "                formatted_prompt = f\"ユーザー: {prompt}\\nシステム: \"\n",
        "\n",
        "            # 入力のエンコード\n",
        "            inputs = self.tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "            generation_args = {\n",
        "                \"max_new_tokens\": max_length,\n",
        "                \"temperature\": temperature,\n",
        "                \"top_p\": 0.95,\n",
        "                \"top_k\": 50,\n",
        "                \"repetition_penalty\": 1.1,\n",
        "                \"do_sample\": temperature > 0.1,\n",
        "                \"pad_token_id\": self.tokenizer.eos_token_id\n",
        "            }\n",
        "\n",
        "            # 生成\n",
        "            output = self.model.generate(\n",
        "                **inputs,\n",
        "                **generation_args\n",
        "            )\n",
        "\n",
        "            # 出力のデコード\n",
        "            generated_text = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "            # プロンプト部分を削除\n",
        "            generated_text = generated_text.replace(formatted_prompt, \"\")\n",
        "\n",
        "            generation_time = time.time() - start_time\n",
        "            return generated_text, generation_time\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"テキスト生成中にエラーが発生しました: {e}\")\n",
        "            generation_time = time.time() - start_time\n",
        "            return f\"エラーが発生しました: {e}\", generation_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1IJsTLP6v2K"
      },
      "source": [
        "**custom_ui.py 追加**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-soh1H-60kk",
        "outputId": "d10a34b2-3fd3-4663-e3fe-7d43197bbe69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting custom_ui.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile custom_ui.py\n",
        "import streamlit as st\n",
        "from streamlit_option_menu import option_menu\n",
        "\n",
        "def create_sidebar():\n",
        "    \"\"\"カスタムサイドバーを作成する関数\"\"\"\n",
        "    with st.sidebar:\n",
        "        selected = option_menu(\n",
        "            \"メインメニュー\",\n",
        "            [\"ホーム\", \"基本要素\", \"レイアウト\", \"入力要素\", \"テーマ設定\"],\n",
        "            icons=[\"house\", \"list-task\", \"columns\", \"input-cursor\", \"palette\"],\n",
        "            menu_icon=\"cast\",\n",
        "            default_index=0,\n",
        "        )\n",
        "\n",
        "        # ダークモード/ライトモードの切り替え\n",
        "        if \"light_mode\" not in st.session_state:\n",
        "            st.session_state.light_mode = True\n",
        "\n",
        "        if st.button(\"🌓 テーマ切替\"):\n",
        "            st.session_state.light_mode = not st.session_state.light_mode\n",
        "\n",
        "        # カスタムCSS\n",
        "        if not st.session_state.light_mode:\n",
        "            st.markdown(\"\"\"\n",
        "            <style>\n",
        "            .main {background-color: #0E1117; color: white;}\n",
        "            .sidebar .sidebar-content {background-color: #262730; color: white;}\n",
        "            </style>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        return selected\n",
        "\n",
        "def page_hourglass():\n",
        "    \"\"\"プログレスバーデモページ\"\"\"\n",
        "    import time\n",
        "\n",
        "    st.subheader(\"改善されたプログレス表示\")\n",
        "    progress_text = \"処理中です。しばらくお待ちください...\"\n",
        "    my_bar = st.progress(0, text=progress_text)\n",
        "    placeholder = st.empty()\n",
        "\n",
        "    for percent_complete in range(100):\n",
        "        time.sleep(0.02)\n",
        "        my_bar.progress(percent_complete + 1, text=f\"{progress_text} ({percent_complete+1}%)\")\n",
        "        if percent_complete % 10 == 0:\n",
        "            placeholder.info(f\"Step {percent_complete // 10 + 1}/10 完了\")\n",
        "\n",
        "    my_bar.empty()\n",
        "    placeholder.empty()\n",
        "    st.success(\"処理が完了しました！\")\n",
        "\n",
        "def show_custom_pages(selected):\n",
        "    \"\"\"選択されたページに基づいてコンテンツを表示\"\"\"\n",
        "    if selected == \"ホーム\":\n",
        "        st.title(\"Streamlit UIデモ（改善版）\")\n",
        "        st.write(\"\"\"このデモアプリは、Streamlitの基本的なUI要素を紹介するものです。\n",
        "        サイドバーから異なるセクションを選択して、様々なStreamlitコンポーネントを試してみてください。\"\"\")\n",
        "\n",
        "        # カード要素の追加\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.info(\"**基本要素**\\n\\nテキスト、ヘッダー、メディアなどの基本的なUI要素\")\n",
        "        with col2:\n",
        "            st.success(\"**レイアウト**\\n\\n列、タブ、エキスパンダーなどのレイアウトオプション\")\n",
        "        with col3:\n",
        "            st.warning(\"**入力要素**\\n\\nボタン、スライダー、テキスト入力などのインタラクティブ要素\")\n",
        "\n",
        "        # プログレスバーデモの表示\n",
        "        if st.button(\"プログレスバーデモを表示\"):\n",
        "            page_hourglass()\n",
        "\n",
        "    # 他のページの実装はapp.pyに任せる\n",
        "    return selected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoRyejCN7IYM"
      },
      "source": [
        "**database.py 書き換え**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-rIp1VF7L1U",
        "outputId": "77becaf3-a102-4a2b-d3eb-04b47f8f2ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting database.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile database.py\n",
        "import sqlite3\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "class ChatDatabase:\n",
        "    def __init__(self, db_file):\n",
        "        self.db_file = db_file\n",
        "        self.initialize_db()\n",
        "\n",
        "    def initialize_db(self):\n",
        "        \"\"\"データベースとテーブルの初期化\"\"\"\n",
        "        conn = sqlite3.connect(self.db_file)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # チャット履歴テーブル\n",
        "        cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            session_id TEXT,\n",
        "            timestamp TEXT,\n",
        "            user_input TEXT,\n",
        "            model_response TEXT,\n",
        "            response_time REAL,\n",
        "            metrics TEXT\n",
        "        )\n",
        "        ''')\n",
        "\n",
        "        # フィードバックテーブル\n",
        "        cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS feedback (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            chat_id INTEGER,\n",
        "            rating INTEGER,\n",
        "            feedback_text TEXT,\n",
        "            timestamp TEXT,\n",
        "            FOREIGN KEY (chat_id) REFERENCES chat_history (id)\n",
        "        )\n",
        "        ''')\n",
        "\n",
        "        # エラーログテーブル（新規追加）\n",
        "        cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS error_logs (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            timestamp TEXT,\n",
        "            error_type TEXT,\n",
        "            error_message TEXT,\n",
        "            stack_trace TEXT,\n",
        "            input_data TEXT\n",
        "        )\n",
        "        ''')\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def save_chat(self, session_id, user_input, model_response, response_time, metrics=None):\n",
        "        \"\"\"チャット履歴を保存\"\"\"\n",
        "        conn = sqlite3.connect(self.db_file)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        timestamp = datetime.now().isoformat()\n",
        "        metrics_json = json.dumps(metrics) if metrics else \"{}\"\n",
        "\n",
        "        cursor.execute(\n",
        "            \"INSERT INTO chat_history (session_id, timestamp, user_input, model_response, response_time, metrics) VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "            (session_id, timestamp, user_input, model_response, response_time, metrics_json)\n",
        "        )\n",
        "\n",
        "        chat_id = cursor.lastrowid\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "        return chat_id\n",
        "\n",
        "    def save_feedback(self, chat_id, rating, feedback_text=\"\"):\n",
        "        \"\"\"フィードバックを保存\"\"\"\n",
        "        conn = sqlite3.connect(self.db_file)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        timestamp = datetime.now().isoformat()\n",
        "\n",
        "        cursor.execute(\n",
        "            \"INSERT INTO feedback (chat_id, rating, feedback_text, timestamp) VALUES (?, ?, ?, ?)\",\n",
        "            (chat_id, rating, feedback_text, timestamp)\n",
        "        )\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def get_chat_history(self, session_id=None, limit=10, offset=0):\n",
        "        \"\"\"チャット履歴を取得\"\"\"\n",
        "        conn = sqlite3.connect(self.db_file)\n",
        "        conn.row_factory = sqlite3.Row\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        if session_id:\n",
        "            cursor.execute(\n",
        "                \"SELECT * FROM chat_history WHERE session_id = ? ORDER BY timestamp DESC LIMIT ? OFFSET ?\",\n",
        "                (session_id, limit, offset)\n",
        "            )\n",
        "        else:\n",
        "            cursor.execute(\n",
        "                \"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT ? OFFSET ?\",\n",
        "                (limit, offset)\n",
        "            )\n",
        "\n",
        "        rows = cursor.fetchall()\n",
        "        history = []\n",
        "\n",
        "        for row in rows:\n",
        "            feedback_cursor = conn.cursor()\n",
        "            feedback_cursor.execute(\n",
        "                \"SELECT rating, feedback_text FROM feedback WHERE chat_id = ?\",\n",
        "                (row['id'],)\n",
        "            )\n",
        "            feedback = feedback_cursor.fetchone()\n",
        "\n",
        "            chat_item = dict(row)\n",
        "            if feedback:\n",
        "                chat_item['feedback_rating'] = feedback['rating']\n",
        "                chat_item['feedback_text'] = feedback['feedback_text']\n",
        "            else:\n",
        "                chat_item['feedback_rating'] = None\n",
        "                chat_item['feedback_text'] = None\n",
        "\n",
        "            try:\n",
        "                chat_item['metrics'] = json.loads(chat_item['metrics'])\n",
        "            except:\n",
        "                chat_item['metrics'] = {}\n",
        "\n",
        "            history.append(chat_item)\n",
        "\n",
        "        conn.close()\n",
        "        return history\n",
        "\n",
        "    def get_total_chat_count(self, session_id=None):\n",
        "        \"\"\"チャット履歴の総数を取得\"\"\"\n",
        "        conn = sqlite3.connect(self.db_file)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        if session_id:\n",
        "            cursor.execute(\n",
        "                \"SELECT COUNT(*) FROM chat_history WHERE session_id = ?\",\n",
        "                (session_id,)\n",
        "            )\n",
        "        else:\n",
        "            cursor.execute(\"SELECT COUNT(*) FROM chat_history\")\n",
        "\n",
        "        count = cursor.fetchone()[0]\n",
        "        conn.close()\n",
        "        return count\n",
        "\n",
        "    def log_error(self, error_type, error_message, stack_trace=\"\", input_data=\"\"):\n",
        "        \"\"\"エラーをログに記録（新規追加）\"\"\"\n",
        "        conn = sqlite3.connect(self.db_file)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        timestamp = datetime.now().isoformat()\n",
        "\n",
        "        cursor.execute(\n",
        "            \"INSERT INTO error_logs (timestamp, error_type, error_message, stack_trace, input_data) VALUES (?, ?, ?, ?, ?)\",\n",
        "            (timestamp, error_type, error_message, stack_trace, input_data)\n",
        "        )\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def get_statistics(self):\n",
        "        \"\"\"チャット統計情報を取得（新規追加）\"\"\"\n",
        "        conn = sqlite3.connect(self.db_file)\n",
        "        conn.row_factory = sqlite3.Row\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # 平均応答時間\n",
        "        cursor.execute(\"SELECT AVG(response_time) as avg_response_time FROM chat_history\")\n",
        "        avg_response_time = cursor.fetchone()['avg_response_time'] or 0\n",
        "\n",
        "        # 総チャット数\n",
        "        cursor.execute(\"SELECT COUNT(*) as total_chats FROM chat_history\")\n",
        "        total_chats = cursor.fetchone()['total_chats'] or 0\n",
        "\n",
        "        # 平均評価\n",
        "        cursor.execute(\"SELECT AVG(rating) as avg_rating FROM feedback\")\n",
        "        avg_rating = cursor.fetchone()['avg_rating'] or 0\n",
        "\n",
        "        # 評価分布\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT rating, COUNT(*) as count\n",
        "            FROM feedback\n",
        "            GROUP BY rating\n",
        "            ORDER BY rating\n",
        "        \"\"\")\n",
        "        rating_distribution = {row['rating']: row['count'] for row in cursor.fetchall()}\n",
        "\n",
        "        conn.close()\n",
        "\n",
        "        return {\n",
        "            'avg_response_time': avg_response_time,\n",
        "            'total_chats': total_chats,\n",
        "            'avg_rating': avg_rating,\n",
        "            'rating_distribution': rating_distribution\n",
        "        }\n",
        "\n",
        "# 使用例\n",
        "if __name__ == \"__main__\":\n",
        "    db = ChatDatabase(\"test.db\")\n",
        "    chat_id = db.save_chat(\"test_session\", \"こんにちは\", \"こんにちは！\", 0.5, {\"bleu_score\": 0.8})\n",
        "    db.save_feedback(chat_id, 5, \"とても良い応答でした\")\n",
        "    history = db.get_chat_history(\"test_session\")\n",
        "    print(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1hK7yN07WwB"
      },
      "source": [
        "**app.py 書き換え**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vh7DCt87ac7",
        "outputId": "c138fdde-a71c-4c2c-ba62-dbf520657c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import uuid\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# ページ設定\n",
        "st.set_page_config(\n",
        "    page_title=\"改善版チャットアプリ\",\n",
        "    page_icon=\"🤖\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\",\n",
        ")\n",
        "\n",
        "# セッションステートの初期化\n",
        "if 'session_id' not in st.session_state:\n",
        "    st.session_state.session_id = str(uuid.uuid4())\n",
        "if 'chat_history' not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "\n",
        "# サイドバーの作成\n",
        "with st.sidebar:\n",
        "    st.title(\"改善版チャットアプリ\")\n",
        "\n",
        "    # テーマ設定\n",
        "    theme = st.selectbox(\n",
        "        \"テーマ\",\n",
        "        [\"ライト\", \"ダーク\", \"ブルー\", \"グリーン\"]\n",
        "    )\n",
        "\n",
        "    # テーマに基づいてカスタムCSSを適用\n",
        "    if theme == \"ダーク\":\n",
        "        st.markdown(\"\"\"\n",
        "        <style>\n",
        "        .main {background-color: #0E1117; color: white;}\n",
        "        .stButton button {background-color: #4CAF50; color: white;}\n",
        "        </style>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "    elif theme == \"ブルー\":\n",
        "        st.markdown(\"\"\"\n",
        "        <style>\n",
        "        .main {background-color: #E8F4F8;}\n",
        "        .stButton button {background-color: #0078D7; color: white;}\n",
        "        </style>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "    elif theme == \"グリーン\":\n",
        "        st.markdown(\"\"\"\n",
        "        <style>\n",
        "        .main {background-color: #E8F8E8;}\n",
        "        .stButton button {background-color: #4CAF50; color: white;}\n",
        "        </style>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # メニュー選択\n",
        "    page = st.radio(\n",
        "        \"メニュー\",\n",
        "        [\"💬 チャット\", \"📚 履歴\", \"📊 分析\"]\n",
        "    )\n",
        "\n",
        "    if page == \"💬 チャット\":\n",
        "        st.subheader(\"設定\")\n",
        "\n",
        "        # 応答スタイル\n",
        "        response_style = st.select_slider(\n",
        "            \"応答スタイル\",\n",
        "            options=[\"簡潔\", \"標準\", \"詳細\"],\n",
        "            value=\"標準\"\n",
        "        )\n",
        "\n",
        "        # セッションリセット\n",
        "        if st.button(\"新しい会話を開始\"):\n",
        "            st.session_state.chat_history = []\n",
        "            st.session_state.session_id = str(uuid.uuid4())\n",
        "            st.success(\"新しい会話を開始しました\")\n",
        "\n",
        "# チャットページ\n",
        "if page == \"💬 チャット\":\n",
        "    st.title(\"チャット\")\n",
        "\n",
        "    # チャット履歴の表示\n",
        "    for chat in st.session_state.chat_history:\n",
        "        # ユーザーメッセージ\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.write(chat[\"user_input\"])\n",
        "\n",
        "        # アシスタントメッセージ\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            st.write(chat[\"model_response\"])\n",
        "\n",
        "            # メトリクスの表示（折りたたみ可能）\n",
        "            if \"metrics\" in chat:\n",
        "                with st.expander(\"パフォーマンス指標\"):\n",
        "                    metrics = chat[\"metrics\"]\n",
        "\n",
        "                    # 基本メトリクス\n",
        "                    cols = st.columns(3)\n",
        "                    with cols[0]:\n",
        "                        st.metric(\"応答時間\", f\"{metrics['response_time']:.2f}秒\")\n",
        "                    with cols[1]:\n",
        "                        st.metric(\"文字数\", f\"{len(chat['model_response'])}\")\n",
        "                    with cols[2]:\n",
        "                        st.metric(\"生成速度\", f\"{len(chat['model_response']) / metrics['response_time']:.1f} 文字/秒\")\n",
        "\n",
        "            # フィードバック\n",
        "            if not chat.get(\"feedback_rating\"):\n",
        "                col1, col2, col3, col4, col5 = st.columns(5)\n",
        "                with col3:\n",
        "                    st.write(\"この回答はいかがでしたか？\")\n",
        "\n",
        "                col1, col2, col3 = st.columns(3)\n",
        "                with col1:\n",
        "                    if st.button(\"👎 悪い\", key=f\"bad_{chat['id']}\"):\n",
        "                        chat[\"feedback_rating\"] = 1\n",
        "                        st.experimental_rerun()\n",
        "                with col2:\n",
        "                    if st.button(\"👍 普通\", key=f\"fair_{chat['id']}\"):\n",
        "                        chat[\"feedback_rating\"] = 3\n",
        "                        st.experimental_rerun()\n",
        "                with col3:\n",
        "                    if st.button(\"👍👍 良い\", key=f\"good_{chat['id']}\"):\n",
        "                        chat[\"feedback_rating\"] = 5\n",
        "                        st.experimental_rerun()\n",
        "            else:\n",
        "                st.success(f\"評価: {'👍' * (chat['feedback_rating'] // 2)}\")\n",
        "\n",
        "    # 新しいメッセージの入力\n",
        "    user_input = st.chat_input(\"メッセージを入力してください\")\n",
        "\n",
        "    if user_input:\n",
        "        # ユーザーメッセージの表示\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.write(user_input)\n",
        "\n",
        "        # アシスタントメッセージの表示\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            message_placeholder = st.empty()\n",
        "\n",
        "            # 応答生成（シミュレーション）\n",
        "            start_time = time.time()\n",
        "            with st.spinner(\"考え中...\"):\n",
        "                # 応答スタイルに基づいて異なる応答を生成\n",
        "                if response_style == \"簡潔\":\n",
        "                    time.sleep(0.5)\n",
        "                    response = f\"質問「{user_input}」への簡潔な回答です。\"\n",
        "                elif response_style == \"詳細\":\n",
        "                    time.sleep(2.0)\n",
        "                    response = f\"\"\"質問「{user_input}」への詳細な回答です。\n",
        "\n",
        "                    ここではもっと詳しい説明を提供します。実際のLLMを使用した場合は、より関連性の高い情報が生成されます。\n",
        "\n",
        "                    追加の詳細情報や例を含めることができます。このデモでは、実際のLLMの代わりに単純なテキスト生成を行っています。\"\"\"\n",
        "                else:  # 標準\n",
        "                    time.sleep(1.0)\n",
        "                    response = f\"質問「{user_input}」への回答です。実際のLLMを使用した場合は、より適切な回答が生成されます。このデモでは単純なテキスト生成を行っています。\"\n",
        "\n",
        "            end_time = time.time()\n",
        "            gen_time = end_time - start_time\n",
        "\n",
        "            message_placeholder.markdown(response)\n",
        "\n",
        "            # メトリクスの計算\n",
        "            metrics = {\n",
        "                \"response_time\": gen_time,\n",
        "                \"text_length\": len(response),\n",
        "                \"generation_speed\": len(response) / gen_time\n",
        "            }\n",
        "\n",
        "            # チャット履歴をセッションに保存\n",
        "            chat_id = len(st.session_state.chat_history)\n",
        "            st.session_state.chat_history.append({\n",
        "                \"id\": chat_id,\n",
        "                \"user_input\": user_input,\n",
        "                \"model_response\": response,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"metrics\": metrics\n",
        "            })\n",
        "\n",
        "            # フィードバックUI\n",
        "            with st.expander(\"パフォーマンス指標\"):\n",
        "                cols = st.columns(3)\n",
        "                with cols[0]:\n",
        "                    st.metric(\"応答時間\", f\"{gen_time:.2f}秒\")\n",
        "                with cols[1]:\n",
        "                    st.metric(\"文字数\", f\"{len(response)}\")\n",
        "                with cols[2]:\n",
        "                    st.metric(\"生成速度\", f\"{len(response) / gen_time:.1f} 文字/秒\")\n",
        "\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                if st.button(\"👎 悪い\", key=f\"bad_new\"):\n",
        "                    st.session_state.chat_history[-1][\"feedback_rating\"] = 1\n",
        "                    st.experimental_rerun()\n",
        "            with col2:\n",
        "                if st.button(\"👍 普通\", key=f\"fair_new\"):\n",
        "                    st.session_state.chat_history[-1][\"feedback_rating\"] = 3\n",
        "                    st.experimental_rerun()\n",
        "            with col3:\n",
        "                if st.button(\"👍👍 良い\", key=f\"good_new\"):\n",
        "                    st.session_state.chat_history[-1][\"feedback_rating\"] = 5\n",
        "                    st.experimental_rerun()\n",
        "\n",
        "# 履歴ページ\n",
        "elif page == \"📚 履歴\":\n",
        "    st.title(\"チャット履歴\")\n",
        "\n",
        "    if not st.session_state.chat_history:\n",
        "        st.info(\"履歴がありません。チャットを始めましょう！\")\n",
        "    else:\n",
        "        # CSV/JSONエクスポート機能\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            # CSVデータの作成\n",
        "            import io\n",
        "            import pandas as pd\n",
        "\n",
        "            csv_data = io.StringIO()\n",
        "            history_df = pd.DataFrame([{\n",
        "                'timestamp': item['timestamp'],\n",
        "                'user_input': item['user_input'],\n",
        "                'model_response': item['model_response'],\n",
        "                'response_time': item['metrics']['response_time'],\n",
        "                'rating': item.get('feedback_rating', 0)\n",
        "            } for item in st.session_state.chat_history])\n",
        "\n",
        "            history_df.to_csv(csv_data, index=False)\n",
        "\n",
        "            st.download_button(\n",
        "                label=\"CSVとしてエクスポート\",\n",
        "                data=csv_data.getvalue(),\n",
        "                file_name=f\"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "                mime=\"text/csv\"\n",
        "            )\n",
        "\n",
        "        with col2:\n",
        "            # JSONエクスポート\n",
        "            json_data = json.dumps([{\n",
        "                'timestamp': item['timestamp'],\n",
        "                'user_input': item['user_input'],\n",
        "                'model_response': item['model_response'],\n",
        "                'metrics': item['metrics'],\n",
        "                'rating': item.get('feedback_rating', 0)\n",
        "            } for item in st.session_state.chat_history], indent=2)\n",
        "\n",
        "            st.download_button(\n",
        "                label=\"JSONとしてエクスポート\",\n",
        "                data=json_data,\n",
        "                file_name=f\"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\",\n",
        "                mime=\"application/json\"\n",
        "            )\n",
        "\n",
        "        # 履歴表示\n",
        "        for i, item in enumerate(st.session_state.chat_history):\n",
        "            with st.expander(f\"{item['timestamp'][:19]} - {item['user_input'][:50]}...\"):\n",
        "                st.subheader(\"ユーザー入力\")\n",
        "                st.write(item['user_input'])\n",
        "\n",
        "                st.subheader(\"モデル応答\")\n",
        "                st.write(item['model_response'])\n",
        "\n",
        "                # メトリクス表示\n",
        "                col1, col2, col3 = st.columns(3)\n",
        "\n",
        "                with col1:\n",
        "                    st.metric(\"応答時間\", f\"{item['metrics']['response_time']:.2f}秒\")\n",
        "\n",
        "                with col2:\n",
        "                    st.metric(\"文字数\", f\"{len(item['model_response'])}\")\n",
        "\n",
        "                with col3:\n",
        "                    if item.get('feedback_rating'):\n",
        "                        st.metric(\"評価\", f\"{item['feedback_rating']}/5\")\n",
        "                    else:\n",
        "                        st.info(\"評価なし\")\n",
        "\n",
        "# 分析ページ\n",
        "elif page == \"📊 分析\":\n",
        "    st.title(\"パフォーマンス分析\")\n",
        "\n",
        "    if not st.session_state.chat_history:\n",
        "        st.info(\"まだデータがありません。チャットを始めて分析データを収集しましょう！\")\n",
        "    else:\n",
        "        # 基本統計\n",
        "        total_chats = len(st.session_state.chat_history)\n",
        "        avg_response_time = sum(chat['metrics']['response_time'] for chat in st.session_state.chat_history) / total_chats\n",
        "        ratings = [chat.get('feedback_rating', 0) for chat in st.session_state.chat_history if chat.get('feedback_rating')]\n",
        "        avg_rating = sum(ratings) / len(ratings) if ratings else 0\n",
        "\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "\n",
        "        with col1:\n",
        "            st.metric(\"総チャット数\", total_chats)\n",
        "\n",
        "        with col2:\n",
        "            st.metric(\"平均応答時間\", f\"{avg_response_time:.2f}秒\")\n",
        "\n",
        "        with col3:\n",
        "            st.metric(\"平均評価\", f\"{avg_rating:.1f}/5\" if ratings else \"評価なし\")\n",
        "\n",
        "        # 応答時間の推移\n",
        "        st.subheader(\"応答時間の推移\")\n",
        "\n",
        "        import pandas as pd\n",
        "        import matplotlib.pyplot as plt\n",
        "\n",
        "        time_data = pd.DataFrame([{\n",
        "            'index': i,\n",
        "            'response_time': chat['metrics']['response_time']\n",
        "        } for i, chat in enumerate(st.session_state.chat_history)])\n",
        "\n",
        "        st.line_chart(time_data.set_index('index')['response_time'])\n",
        "\n",
        "        # 評価分布\n",
        "        st.subheader(\"評価分布\")\n",
        "\n",
        "        from collections import Counter\n",
        "\n",
        "        rating_counts = Counter(ratings)\n",
        "        rating_df = pd.DataFrame({\n",
        "            '評価': list(rating_counts.keys()),\n",
        "            '回数': list(rating_counts.values())\n",
        "        })\n",
        "\n",
        "        if not rating_df.empty:\n",
        "            fig, ax = plt.subplots()\n",
        "            ax.bar(rating_df['評価'], rating_df['回数'])\n",
        "            ax.set_xlabel('評価点数')\n",
        "            ax.set_ylabel('回数')\n",
        "            ax.set_xticks(range(1, 6))\n",
        "            ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "            st.pyplot(fig)\n",
        "        else:\n",
        "            st.info(\"まだ評価データがありません。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBQyTTWTELSP",
        "outputId": "a91611cd-3c58-4a1b-e3b3-1c9867ae7f7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "公開URL: https://612c-34-125-210-255.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.210.255:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"公開URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxliKOTawSDe"
      },
      "source": [
        "アプリケーションの機能としては、チャット機能や履歴閲覧があります。\n",
        "\n",
        "これらの機能を実現するためには、StreamlitによるUI部分だけではなく、SQLiteを使用したチャット履歴の保存やLLMのモデルを呼び出した推論などの処理を組み合わせることで実現しています。\n",
        "\n",
        "- **`app.py`**: アプリケーションのエントリーポイント。チャット機能、履歴閲覧、サンプルデータ管理のUIを提供します。\n",
        "- **`ui.py`**: チャットページや履歴閲覧ページなど、アプリケーションのUIロジックを管理します。\n",
        "- **`llm.py`**: LLMモデルのロードとテキスト生成を行うモジュール。\n",
        "- **`database.py`**: SQLiteデータベースを使用してチャット履歴やフィードバックを保存・管理します。\n",
        "- **`metrics.py`**: BLEUスコアやコサイン類似度など、回答の評価指標を計算するモジュール。\n",
        "- **`data.py`**: サンプルデータの作成やデータベースの初期化を行うモジュール。\n",
        "- **`config.py`**: アプリケーションの設定（モデル名やデータベースファイル名）を管理します。\n",
        "- **`requirements.txt`**: このアプリケーションを実行するために必要なPythonパッケージ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvm8sWFPELSP"
      },
      "source": [
        "後片付けとして、使う必要のないngrokのトンネルを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "WFJC2TmZELSP"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUXhIzV7ELSP"
      },
      "source": [
        "# 03_FastAPI\n",
        "\n",
        "ディレクトリ「03_FastAPI」に移動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4ejjDLxr3kfC"
      },
      "outputs": [],
      "source": [
        "# %cd /content/lecture-ai-engineering/day1/03_FastAPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f45TDsNzELSQ"
      },
      "source": [
        "必要なライブラリをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uv6glCz5a7Z"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfrmE2VmELSQ"
      },
      "source": [
        "ngrokとhuggigfaceのトークンを使用して、認証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ELzWhMFORRIO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /Users/yamadayuuhei/Library/Application Support/ngrok/ngrok.yml\n",
            "pyenv: invalid version `/Users/yamadayuuhei/Study/AIE/lecture-ai-engineering/.venv/bin/python' ignored in `/Users/yamadayuuhei/Study/AIE/lecture-ai-engineering/.python-version'\n",
            "pyenv: invalid version `/Users/yamadayuuhei/Study/AIE/lecture-ai-engineering/.venv/bin/python' ignored in `/Users/yamadayuuhei/Study/AIE/lecture-ai-engineering/.python-version'\n",
            "pyenv: huggingface-cli: command not found\n",
            "\n",
            "The `huggingface-cli' command exists in these Python versions:\n",
            "  3.12.4\n",
            "\n",
            "Note: See 'pyenv help global' for tips on allowing both\n",
            "      python2 and python3 to be found.\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-wztc2CELSQ"
      },
      "source": [
        "アプリを起動します。\n",
        "\n",
        "「02_streamlit_app」から続けて「03_FastAPI」を実行している場合は、モデルのダウンロードが済んでいるため、すぐにサービスが立ち上がります。\n",
        "\n",
        "「03_FastAPI」のみを実行している場合は、初回の起動時にモデルのダウンロードが始まるので、モデルのダウンロードが終わるまで数分間待ちましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/yamadayuuhei/Study/AIE/lecture-ai-engineering/day1/03_FastAPI\n"
          ]
        }
      ],
      "source": [
        "cd 03_FastAPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting filelock (from transformers)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
            "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Downloading numpy-2.2.5-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0 (from transformers)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Using cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "Collecting requests (from transformers)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
            "Collecting tqdm>=4.27 (from transformers)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
            "  Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "Downloading numpy-2.2.5-cp312-cp312-macosx_14_0_arm64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
            "Using cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
            "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
            "Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.6/159.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl (196 kB)\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Installing collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, packaging, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed certifi-2025.4.26 charset-normalizer-3.4.1 filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.30.2 idna-3.10 numpy-2.2.5 packaging-25.0 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.3 typing-extensions-4.13.2 urllib3-2.4.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "meQ4SwISn3IQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/yamadayuuhei/Study/AIE/simplechat/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
            "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/yamadayuuhei/Study/AIE/lecture-ai-engineering/day1/03_FastAPI/app.py\", line 3, in <module>\n",
            "    from transformers import pipeline\n",
            "ModuleNotFoundError: No module named 'transformers'\n"
          ]
        }
      ],
      "source": [
        "!python app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLubjIhbELSR"
      },
      "source": [
        "FastAPIが起動すると、APIとクライアントが通信するためのURL（エンドポイント）が作られます。\n",
        "\n",
        "URLが作られるのと合わせて、Swagger UIというWebインターフェースが作られます。\n",
        "\n",
        "Swagger UIにアクセスすることで、APIの仕様を確認できたり、APIをテストすることができます。\n",
        "\n",
        "Swagger UIを利用することで、APIを通してLLMを動かしてみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgumW3mGELSR"
      },
      "source": [
        "後片付けとして、使う必要のないngrokのトンネルを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJymTZio-WPJ"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
