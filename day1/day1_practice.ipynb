{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSpnWBP5ELSI"
      },
      "source": [
        "# å®Ÿè·µæ¼”ç¿’ Day 1ï¼šstreamlitã¨FastAPIã®ãƒ‡ãƒ¢\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ä»¥ä¸‹ã®å†…å®¹ã‚’å­¦ç¿’ã—ã¾ã™ã€‚\n",
        "\n",
        "- å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ç’°å¢ƒè¨­å®š\n",
        "- Hugging Faceã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸStreamlitã®ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒª\n",
        "- FastAPIã¨ngrokã‚’ä½¿ç”¨ã—ãŸAPIã®å…¬é–‹æ–¹æ³•\n",
        "\n",
        "æ¼”ç¿’ã‚’å§‹ã‚ã‚‹å‰ã«ã€HuggingFaceã¨ngrokã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã—ã€\n",
        "ãã‚Œãã‚Œã®APIãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "\n",
        "\n",
        "æ¼”ç¿’ã®æ™‚é–“ã§ã¯ã€ä»¥ä¸‹ã®3ã¤ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’é †ã«èª¬æ˜ã—ã¾ã™ã€‚\n",
        "\n",
        "1. 01_streamlit_UI\n",
        "2. 02_streamlit_app\n",
        "3. 03_FastAPI\n",
        "\n",
        "2ã¤ç›®ã‚„3ã¤ç›®ã‹ã‚‰ã§ã‚‚å§‹ã‚ã‚‰ã‚Œã‚‹æ§˜ã«ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "å¾©ç¿’ã®éš›ã«ã‚‚ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’å½¹ç«‹ã¦ã¦ã„ãŸã ã‘ã‚Œã°ã¨æ€ã„ã¾ã™ã€‚\n",
        "\n",
        "### æ³¨æ„äº‹é …\n",
        "ã€Œ02_streamlit_appã€ã¨ã€Œ03_FastAPIã€ã§ã¯ã€GPUã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
        "\n",
        "ã“ã‚Œã‚‰ã‚’å®Ÿè¡Œã™ã‚‹éš›ã¯ã€Google Colabç”»é¢ä¸Šã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ã€Œç·¨é›†ã€â†’ ã€Œãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®è¨­å®šã€\n",
        "\n",
        "ã€Œãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ãƒ¼ã€ã®é …ç›®ã®ä¸­ã‹ã‚‰ã€ã€ŒT4 GPUã€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã€ŒCPUã€ã«ãªã£ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhtHkJOgELSL"
      },
      "source": [
        "# ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼ˆ1~3å…±æœ‰ï¼‰\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-FjBp4MMQHM"
      },
      "source": [
        "GitHubã‹ã‚‰æ¼”ç¿’ç”¨ã®ã‚³ãƒ¼ãƒ‰ã‚’Cloneã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIXMavdDEP8U",
        "outputId": "1fafed51-a8f6-4147-bb25-43e65ac3df73"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/matsuolab/lecture-ai-engineering.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC8n7yZ_vs1K"
      },
      "source": [
        "å¿…è¦ãªAPIãƒˆãƒ¼ã‚¯ãƒ³ã‚’.envã«è¨­å®šã—ã¾ã™ã€‚\n",
        "\n",
        "ã€Œlecture-ai-engineering/day1ã€ã®é…ä¸‹ã«ã€ã€Œ.env_templateã€ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "éš ã—ãƒ•ã‚¡ã‚¤ãƒ«ã®ãŸã‚è¡¨ç¤ºã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ç”»é¢å·¦å´ã®ã‚ã‚‹ã€ç›®ã®ã‚¢ã‚¤ã‚³ãƒ³ã®ã€Œéš ã—ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤ºã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ã€Œ.env_templateã€ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã€Œ.envã€ã«å¤‰æ›´ã—ã¾ã™ã€‚ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªä¸­èº«ã«ãªã£ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "\n",
        "```\n",
        "HUGGINGFACE_TOKEN=\"hf-********\"\n",
        "NGROK_TOKEN=\"********\"\n",
        "```\n",
        "ãƒ€ãƒ–ãƒ«ã‚¯ã‚ªãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§å›²ã¾ã‚ŒãŸæ–‡å­—åˆ—ã‚’Huggingfaceã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã€ngrokã®èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã§æ›¸ãå¤‰ãˆã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ãã‚Œãã‚Œã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒä½œæˆæ¸ˆã¿ã§ã‚ã‚Œã°ã€ä»¥ä¸‹ã®URLã‹ã‚‰ãã‚Œãã‚Œã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã§ãã¾ã™ã€‚\n",
        "\n",
        "- Huggingfaceã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³\n",
        "https://huggingface.co/docs/hub/security-tokens\n",
        "\n",
        "- ngrokã®èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³\n",
        "https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "æ›¸ãæ›ãˆãŸã‚‰ã€ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã®PCã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "ã€Œ01_streamlit_UIã€ã‹ã‚‰ã€Œ02_streamlit_appã€ã¸é€²ã‚€éš›ã«ã€CPUã‹ã‚‰GPUã®åˆ©ç”¨ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ãŸã‚ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒä¸€åº¦åˆ‡ã‚Œã¦ã—ã¾ã„ã¾ã™ã€‚\n",
        "\n",
        "ãã®éš›ã«ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šã—ãŸã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã¯å†ä½œæˆã™ã‚‹ã“ã¨ã«ãªã‚‹ã®ã§ã€ãã®æ‰‹é–“ã‚’æ¸›ã‚‰ã™ãŸã‚ã«ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãŠãã¨è‰¯ã„ã§ã™ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py1BFS5RqcSS"
      },
      "source": [
        "ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ç’°å¢ƒå¤‰æ•°ã¨ã—ã¦è¨­å®šã—ã¾ã™ã€‚æ¬¡ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã€æœ€çµ‚çš„ã«ã€ŒTrueã€ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚Œã°ã†ã¾ãèª­ã¿è¾¼ã‚ã¦ã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvEowFfg5lrq",
        "outputId": "baa8488d-aa6f-45b6-c7eb-0f06bd6a8165"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# !pip install python-dotenv\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# %cd /content/lecture-ai-engineering/day1\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTE7nUlM160Q"
      },
      "source": [
        "ç’°å¢ƒå¤‰æ•°ã‚’ä¸€æ™‚çš„ã«ä¿å­˜ã—ã¦ãŠãã‚³ãƒ¼ãƒ‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BLkrs1sc2CTT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def save_env_backup():\n",
        "        env_backup = {\n",
        "                \"HUGGINGFACE_TOKEN\": os.environ.get(\"HUGGINGFACE_TOKEN\"),\n",
        "                \"NGROK_TOKEN\": os.environ.get(\"NGROK_TOKEN\")\n",
        "            }\n",
        "        with open('/content/env_backup.json', 'w') as f:\n",
        "              json.dump(env_backup, f)\n",
        "        print(\"ç’°å¢ƒå¤‰æ•°ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ã¾ã—ãŸã€‚ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆ‡æ–­ã•ã‚ŒãŸå ´åˆã¯ restore_env_backup() ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
        "\n",
        "        # ç’°å¢ƒå¤‰æ•°ã‚’å¾©å…ƒã™ã‚‹é–¢æ•°\n",
        "        def restore_env_backup():\n",
        "            try:\n",
        "                with open('/content/env_backup.json', 'r') as f:\n",
        "                    env_backup = json.load(f)\n",
        "\n",
        "                # ç’°å¢ƒå¤‰æ•°ã‚’å¾©å…ƒ\n",
        "                for key, value in env_backup.items():\n",
        "                    os.environ[key] = value\n",
        "\n",
        "                # .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ä½œæˆ\\n\",\n",
        "                with open('/content/lecture-ai-engineering/day1/.env', 'w') as f:\n",
        "                    for key, value in env_backup.items():\n",
        "                        f.write(f\"{key}={value}\")\n",
        "\n",
        "                print(\"ç’°å¢ƒå¤‰æ•°ã‚’å¾©å…ƒã—ã¾ã—ãŸã€‚\")\n",
        "                return True\n",
        "            except FileNotFoundError:\n",
        "                print(\"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã‚’æ‰‹å‹•ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚\")\n",
        "                return False\n",
        "\n",
        "        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ\n",
        "        save_env_backup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os0Yk6gaELSM"
      },
      "source": [
        "# 01_streamlit_UI\n",
        "\n",
        "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€Œ01_streamlit_UIã€ã«ç§»å‹•ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S28XgOm0ELSM",
        "outputId": "113a90ce-059f-4644-cd6e-f361dd533d3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/lecture-ai-engineering/day1/01_streamlit_UI\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/01_streamlit_UI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVp-aEIkELSM"
      },
      "source": [
        "å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nBe41LFiELSN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "!pip install streamlit-option-menu streamlit-authenticator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw3EGhkd4MZV"
      },
      "source": [
        "**æ–°ã—ã„ UI ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’è¿½åŠ **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6aCDSi04WwI",
        "outputId": "97e9e1f5-e609-4134-f0a6-47e6ddc2e3c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting custom_ui.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile custom_ui.py\n",
        "\"\"\"\n",
        "custom_ui.py\n",
        "-----------------\n",
        "Streamlit ç”¨ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼†ã‚«ã‚¹ã‚¿ãƒ ãƒšãƒ¼ã‚¸éƒ¨å“ã€‚\n",
        "â€¢ ãƒ¡ãƒ‹ãƒ¥ãƒ¼é¸æŠãƒ»ãƒ†ãƒ¼ãƒåˆ‡æ›¿\n",
        "â€¢ ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã®ã‚«ãƒ¼ãƒ‰ã¨ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "import time\n",
        "import streamlit as st\n",
        "from streamlit_option_menu import option_menu\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# ã‚µã‚¤ãƒ‰ãƒãƒ¼\n",
        "# ----------------------------------------------------------------------\n",
        "_MENU_ITEMS = [\"ãƒ›ãƒ¼ãƒ \", \"åŸºæœ¬è¦ç´ \", \"ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ\", \"å…¥åŠ›è¦ç´ \", \"ãƒ†ãƒ¼ãƒè¨­å®š\"]\n",
        "_ICONS = [\"house\", \"list-task\", \"columns\", \"input-cursor\", \"palette\"]\n",
        "\n",
        "\n",
        "def _apply_dark_theme(enable_dark: bool) -> None:\n",
        "    \"\"\"ãƒ€ãƒ¼ã‚¯ãƒ†ãƒ¼ãƒã‚’ CSS ã§é©ç”¨ï¼è§£é™¤ã™ã‚‹ã€‚\"\"\"\n",
        "    if enable_dark:\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "            <style>\n",
        "            .main {background-color: #0E1117; color: #FFFFFF;}\n",
        "            .sidebar .sidebar-content {background-color: #262730; color: #FFFFFF;}\n",
        "            </style>\n",
        "            \"\"\",\n",
        "            unsafe_allow_html=True,\n",
        "        )\n",
        "\n",
        "\n",
        "def create_sidebar() -> str:\n",
        "    \"\"\"\n",
        "    ã‚«ã‚¹ã‚¿ãƒ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’ç”Ÿæˆã—ã€é¸æŠã•ã‚ŒãŸãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è¿”ã™ã€‚\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        ç¾åœ¨é¸æŠä¸­ã®ãƒšãƒ¼ã‚¸åã€‚\n",
        "    \"\"\"\n",
        "    with st.sidebar:\n",
        "        selected = option_menu(\n",
        "            menu_title=\"ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼\",\n",
        "            options=_MENU_ITEMS,\n",
        "            icons=_ICONS,\n",
        "            menu_icon=\"cast\",\n",
        "            default_index=0,\n",
        "        )\n",
        "\n",
        "        # ãƒ†ãƒ¼ãƒåˆ‡æ›¿ã‚¹ã‚¤ãƒƒãƒ\n",
        "        if \"light_mode\" not in st.session_state:\n",
        "            st.session_state.light_mode = True\n",
        "\n",
        "        if st.button(\"ğŸŒ“ ãƒ†ãƒ¼ãƒåˆ‡æ›¿\"):\n",
        "            st.session_state.light_mode = not st.session_state.light_mode\n",
        "\n",
        "    # ã‚µã‚¤ãƒ‰ãƒãƒ¼å¤–ã§ãƒ†ãƒ¼ãƒé©ç”¨ï¼ˆCSS ã¯ 1 åº¦ã®ã¿æŒ¿å…¥ï¼‰\n",
        "    _apply_dark_theme(not st.session_state.light_mode)\n",
        "\n",
        "    return selected\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£\n",
        "# ----------------------------------------------------------------------\n",
        "def page_hourglass() -> None:\n",
        "    \"\"\"ãƒ‡ãƒ¢ç”¨ã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’è¡¨ç¤ºã™ã‚‹ãƒšãƒ¼ã‚¸ã€‚\"\"\"\n",
        "    st.subheader(\"æ”¹å–„ã•ã‚ŒãŸãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º\")\n",
        "    progress_text = \"å‡¦ç†ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...\"\n",
        "    bar = st.progress(0, text=progress_text)\n",
        "    placeholder = st.empty()\n",
        "\n",
        "    for percent in range(100):\n",
        "        time.sleep(0.02)\n",
        "        bar.progress(percent + 1, text=f\"{progress_text} ({percent + 1}%)\")\n",
        "        if percent % 10 == 0:\n",
        "            placeholder.info(f\"Step {percent // 10 + 1}/10 å®Œäº†\")\n",
        "\n",
        "    bar.empty()\n",
        "    placeholder.empty()\n",
        "    st.success(\"å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# ãƒšãƒ¼ã‚¸åˆ‡æ›¿ãƒãƒ–\n",
        "# ----------------------------------------------------------------------\n",
        "def show_custom_pages(selected: str) -> str:\n",
        "    \"\"\"\n",
        "    é¸æŠã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã«å¯¾å¿œã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æç”»ã™ã‚‹ã€‚\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    selected : str\n",
        "        create_sidebar ã‹ã‚‰è¿”ã•ã‚ŒãŸãƒšãƒ¼ã‚¸åã€‚\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        åŒã˜å€¤ã‚’è¿”ã™ã ã‘ï¼ˆå‘¼ã³å‡ºã—å…ƒã§ã®å†åˆ©ç”¨ç”¨ï¼‰ã€‚\n",
        "    \"\"\"\n",
        "    if selected == \"ãƒ›ãƒ¼ãƒ \":\n",
        "        _render_home()\n",
        "\n",
        "    # ãã®ã»ã‹ã®ãƒšãƒ¼ã‚¸ã¯ app.py ã§å‡¦ç†\n",
        "    return selected\n",
        "\n",
        "\n",
        "def _render_home() -> None:\n",
        "    \"\"\"ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã‚’æç”»ã€‚\"\"\"\n",
        "    st.title(\"Streamlit UIãƒ‡ãƒ¢ï¼ˆæ”¹å–„ç‰ˆï¼‰\")\n",
        "    st.write(\n",
        "        \"\"\"\n",
        "        ã“ã®ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒªã¯ã€Streamlit ã®åŸºæœ¬çš„ãª UI è¦ç´ ã‚’ç´¹ä»‹ã™ã‚‹ã‚‚ã®ã§ã™ã€‚\n",
        "        ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ç•°ãªã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠã—ã¦ã€ã•ã¾ã–ã¾ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ãŠè©¦ã—ãã ã•ã„ã€‚\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # ã‚«ãƒ¼ãƒ‰é¢¨ã« 3 ã‚«ãƒ©ãƒ ã§æ©Ÿèƒ½æ¡ˆå†…\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    with col1:\n",
        "        st.info(\"**åŸºæœ¬è¦ç´ **\\n\\nãƒ†ã‚­ã‚¹ãƒˆã€ãƒ˜ãƒƒãƒ€ãƒ¼ã€ãƒ¡ãƒ‡ã‚£ã‚¢ãªã©\")\n",
        "    with col2:\n",
        "        st.success(\"**ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ**\\n\\nåˆ—ã€ã‚¿ãƒ–ã€ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ãªã©\")\n",
        "    with col3:\n",
        "        st.warning(\"**å…¥åŠ›è¦ç´ **\\n\\nãƒœã‚¿ãƒ³ã€ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã€ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãªã©\")\n",
        "\n",
        "    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®ãƒ‡ãƒ¢èµ·å‹•\n",
        "    if st.button(\"ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ãƒ‡ãƒ¢ã‚’è¡¨ç¤º\"):\n",
        "        page_hourglass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyw6VHaTELSN"
      },
      "source": [
        "ngrokã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€èªè¨¼ã‚’è¡Œã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYw1q0iXELSN",
        "outputId": "393d9179-e244-4452-bfde-50956165de5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x2rBm74meW9"
      },
      "source": [
        "**app.pyã®æ›¸ãæ›ãˆ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqPQcRxLmikL",
        "outputId": "b02a3da3-ceeb-465d-c8cd-56b833379189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\"\"\"Streamlit UI Demo â€” cleaned & refactored\n",
        "------------------------------------------------\n",
        "A singleâ€‘file demo app showcasing basic Streamlit components.\n",
        "Split into small render_* functions for readability.\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "import io\n",
        "from datetime import date as dt_date\n",
        "from typing import Callable, Dict\n",
        "\n",
        "import altair as alt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "\n",
        "from custom_ui import create_sidebar, show_custom_pages\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# ãƒšãƒ¼ã‚¸å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "def random_df(rows: int = 20, cols: int = 3, colnames: list[str] | None = None) -> pd.DataFrame:\n",
        "    \"\"\"ãƒ©ãƒ³ãƒ€ãƒ  DataFrame ã‚’ç”Ÿæˆã€‚\"\"\"\n",
        "    if colnames is None:\n",
        "        colnames = list(\"ABC\")[:cols]\n",
        "    return pd.DataFrame(np.random.randn(rows, cols), columns=colnames)\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# å€‹åˆ¥ãƒšãƒ¼ã‚¸æç”»é–¢æ•°\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "def render_basic() -> None:\n",
        "    \"\"\"åŸºæœ¬ UI è¦ç´ ãƒšãƒ¼ã‚¸\"\"\"\n",
        "    st.title(\"åŸºæœ¬è¦ç´ \")\n",
        "\n",
        "    # --- ãƒ†ã‚­ã‚¹ãƒˆé¡ ---\n",
        "    st.header(\"ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ \")\n",
        "    st.text(\"ã“ã‚Œã¯é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚\")\n",
        "    st.markdown(\"**ã“ã‚Œã¯ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚** *ã‚¤ã‚¿ãƒªãƒƒã‚¯* ã‚„ `ã‚³ãƒ¼ãƒ‰` ã‚‚ä½¿ãˆã¾ã™ã€‚\")\n",
        "    st.info(\"ã“ã‚Œã¯æƒ…å ±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚\")\n",
        "    st.warning(\"ã“ã‚Œã¯è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚\")\n",
        "    st.error(\"ã“ã‚Œã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚\")\n",
        "    st.success(\"ã“ã‚Œã¯æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚\")\n",
        "\n",
        "    # --- ãƒ¡ãƒ‡ã‚£ã‚¢è¦ç´  ---\n",
        "    st.header(\"ãƒ¡ãƒ‡ã‚£ã‚¢è¦ç´ \")\n",
        "    tab_chart, tab_df, tab_img = st.tabs([\"ğŸ“ˆ ãƒãƒ£ãƒ¼ãƒˆ\", \"ğŸ—ƒ DataFrame\", \"ğŸ–¼ ç”»åƒ\"])\n",
        "\n",
        "    with tab_chart:\n",
        "        st.subheader(\"æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•\")\n",
        "        chart_data = random_df()\n",
        "        st.line_chart(chart_data)\n",
        "\n",
        "        st.subheader(\"Altair ãƒãƒ£ãƒ¼ãƒˆ\")\n",
        "        c = (\n",
        "            alt.Chart(chart_data.reset_index())\n",
        "            .mark_circle()\n",
        "            .encode(x=\"index\", y=\"A\", size=\"B\", color=\"C\", tooltip=[\"A\", \"B\", \"C\"])\n",
        "            .interactive()\n",
        "        )\n",
        "        st.altair_chart(c, use_container_width=True)\n",
        "\n",
        "    with tab_df:\n",
        "        st.subheader(\"DataFrame ã®è¡¨ç¤º\")\n",
        "        df = pd.DataFrame({\n",
        "            \"åå‰\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
        "            \"å¹´é½¢\": [24, 42, 18, 31],\n",
        "            \"éƒ½å¸‚\": [\"æ±äº¬\", \"å¤§é˜ª\", \"äº¬éƒ½\", \"åå¤å±‹\"],\n",
        "        })\n",
        "        st.dataframe(df, use_container_width=True)\n",
        "        st.download_button(\"CSVã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\", df.to_csv(index=False, encoding=\"utf-8-sig\"), \"sample_data.csv\", \"text/csv\")\n",
        "\n",
        "    with tab_img:\n",
        "        st.subheader(\"å‹•çš„ã«ç”Ÿæˆã—ãŸç”»åƒ\")\n",
        "        fig, ax = plt.subplots()\n",
        "        x = np.linspace(0, 10, 100)\n",
        "        ax.plot(x, np.sin(x))\n",
        "        ax.set_title(\"ã‚µã‚¤ãƒ³æ³¢\")\n",
        "        ax.grid(True)\n",
        "        buf = io.BytesIO()\n",
        "        fig.savefig(buf, format=\"png\")\n",
        "        st.image(buf.getvalue(), caption=\"å‹•çš„ã«ç”Ÿæˆã•ã‚ŒãŸã‚µã‚¤ãƒ³æ³¢\", use_column_width=True)\n",
        "\n",
        "\n",
        "def render_layout() -> None:\n",
        "    \"\"\"ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¦ç´ ãƒšãƒ¼ã‚¸\"\"\"\n",
        "    st.title(\"ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¦ç´ \")\n",
        "\n",
        "    st.header(\"ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ\")\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    with col1:\n",
        "        st.subheader(\"ã‚«ãƒ©ãƒ 1\")\n",
        "        st.image(\"https://via.placeholder.com/150\", caption=\"ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒ\")\n",
        "    with col2:\n",
        "        st.subheader(\"ã‚«ãƒ©ãƒ 2\")\n",
        "        st.metric(\"æ¸©åº¦\", \"28Â°C\", \"1.2Â°C\")\n",
        "    with col3:\n",
        "        st.subheader(\"ã‚«ãƒ©ãƒ 3\")\n",
        "        st.metric(\"æ¹¿åº¦\", \"65%\", \"-4%\", delta_color=\"inverse\")\n",
        "\n",
        "    st.header(\"ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼\")\n",
        "    with st.expander(\"è©³ç´°ã‚’è¡¨ç¤º\"):\n",
        "        st.write(\"\"\"\n",
        "            ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€é•·ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ˜ã‚ŠãŸãŸã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
        "            ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¿…è¦ãªã¨ãã«å±•é–‹ã§ãã‚‹ãŸã‚ã€ç”»é¢ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç¯€ç´„ã§ãã¾ã™ã€‚\n",
        "        \"\"\")\n",
        "        st.image(\"https://via.placeholder.com/400x200\", caption=\"å¤§ããªãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒ\")\n",
        "\n",
        "    st.header(\"ã‚¿ãƒ–\")\n",
        "    tab1, tab2, tab3 = st.tabs([\"Tab 1\", \"Tab 2\", \"Tab 3\"])\n",
        "    with tab1:\n",
        "        st.bar_chart(random_df(10, 3, [\"X\", \"Y\", \"Z\"]))\n",
        "    with tab2:\n",
        "        st.line_chart(pd.DataFrame(np.sin(np.linspace(0, 10, 100))))\n",
        "    with tab3:\n",
        "        st.area_chart(random_df(10).cumsum())\n",
        "\n",
        "\n",
        "def render_inputs() -> None:\n",
        "    \"\"\"å…¥åŠ›è¦ç´ ãƒšãƒ¼ã‚¸\"\"\"\n",
        "    st.title(\"å…¥åŠ›è¦ç´ \")\n",
        "\n",
        "    # --- ãƒœã‚¿ãƒ³ ---\n",
        "    st.header(\"ãƒœã‚¿ãƒ³\")\n",
        "    if st.button(\"ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„\"):\n",
        "        st.success(\"ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚Œã¾ã—ãŸï¼\")\n",
        "\n",
        "    # --- ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ ---\n",
        "    st.header(\"ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹\")\n",
        "    if st.checkbox(\"ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’è¡¨ç¤º\"):\n",
        "        st.write(\"ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãŒã‚ªãƒ³ã«ãªã£ã¦ã„ã¾ã™ã€‚\")\n",
        "\n",
        "    # --- ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ ---\n",
        "    st.header(\"ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³\")\n",
        "    genre = st.radio(\"å¥½ããªéŸ³æ¥½ã‚¸ãƒ£ãƒ³ãƒ«ã¯ï¼Ÿ\", (\"ãƒ­ãƒƒã‚¯\", \"ãƒãƒƒãƒ—\", \"ã‚¸ãƒ£ã‚º\", \"ã‚¯ãƒ©ã‚·ãƒƒã‚¯\"))\n",
        "    if genre:\n",
        "        st.write(f\"ã‚ãªãŸã¯ {genre} ã‚’é¸æŠã—ã¾ã—ãŸã€‚\")\n",
        "\n",
        "    # --- ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ ---\n",
        "    st.header(\"ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹\")\n",
        "    color = st.selectbox(\"å¥½ããªè‰²ã¯ï¼Ÿ\", (\"èµ¤\", \"é’\", \"ç·‘\", \"é»„è‰²\"))\n",
        "    st.write(f\"ã‚ãªãŸãŒé¸ã‚“ã ã®ã¯: {color}\")\n",
        "\n",
        "    # --- ãƒãƒ«ãƒã‚»ãƒ¬ã‚¯ãƒˆ ---\n",
        "    st.header(\"ãƒãƒ«ãƒã‚»ãƒ¬ã‚¯ãƒˆ\")\n",
        "    fruits = st.multiselect(\n",
        "        \"å¥½ããªæœç‰©ã¯ï¼Ÿ\",\n",
        "        [\"ã‚Šã‚“ã”\", \"ãƒãƒŠãƒŠ\", \"ã‚ªãƒ¬ãƒ³ã‚¸\", \"ã¶ã©ã†\", \"ã„ã¡ã”\"],\n",
        "        default=[\"ã‚Šã‚“ã”\", \"ãƒãƒŠãƒŠ\"],\n",
        "    )\n",
        "    st.write(\"ã‚ãªãŸãŒé¸ã‚“ã ã®ã¯: \" + \", \".join(fruits))\n",
        "\n",
        "    # --- ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ ---\n",
        "    st.header(\"ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼\")\n",
        "    age = st.slider(\"ã‚ãªãŸã®å¹´é½¢ã¯ï¼Ÿ\", 0, 100, 25)\n",
        "    st.write(f\"ã‚ãªãŸã®å¹´é½¢: {age}æ­³\")\n",
        "\n",
        "    # --- ç¯„å›²ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ ---\n",
        "    values = st.slider(\"å€¤ã®ç¯„å›²ã‚’é¸æŠ:\", 0.0, 100.0, (25.0, 75.0))\n",
        "    st.write(f\"é¸æŠã•ã‚ŒãŸç¯„å›²: {values[0]} ã‹ã‚‰ {values[1]}\")\n",
        "\n",
        "    # --- æ—¥ä»˜å…¥åŠ› ---\n",
        "    st.header(\"æ—¥ä»˜å…¥åŠ›\")\n",
        "    birth = st.date_input(\"ç”Ÿå¹´æœˆæ—¥ã‚’é¸æŠã—ã¦ãã ã•ã„\", dt_date(2000, 1, 1))\n",
        "    st.write(f\"ã‚ãªãŸã®ç”Ÿå¹´æœˆæ—¥: {birth}\")\n",
        "\n",
        "    # --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ ---\n",
        "    st.header(\"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼\")\n",
        "    uploaded = st.file_uploader(\"ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„\", type=[\"csv\", \"xlsx\", \"txt\", \"jpg\", \"png\"])\n",
        "    if uploaded is not None:\n",
        "        st.write(f\"ãƒ•ã‚¡ã‚¤ãƒ«å: {uploaded.name} â€” {uploaded.size} bytes\")\n",
        "        if uploaded.type.startswith(\"image\"):\n",
        "            st.image(uploaded, caption=\"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ\", use_column_width=True)\n",
        "        elif uploaded.type == \"text/plain\":\n",
        "            string_data = io.StringIO(uploaded.getvalue().decode()).read()\n",
        "            st.text_area(\"ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹\", string_data, height=200)\n",
        "        elif uploaded.type == \"text/csv\":\n",
        "            st.dataframe(pd.read_csv(uploaded), use_container_width=True)\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# ãƒ†ãƒ¼ãƒè¨­å®šãƒšãƒ¼ã‚¸ã¯ custom_ui.py å†…ã® CSS ã§åˆ¶å¾¡\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "# ----------------------------------------------------------------------------\n",
        "# ãƒšãƒ¼ã‚¸è¨­å®š & ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "def main() -> None:\n",
        "    st.set_page_config(\n",
        "        page_title=\"Streamlit UIãƒ‡ãƒ¢ï¼ˆæ”¹å–„ç‰ˆï¼‰\",\n",
        "        page_icon=\"ğŸ§Š\",\n",
        "        layout=\"wide\",\n",
        "        initial_sidebar_state=\"expanded\",\n",
        "    )\n",
        "\n",
        "    selected = create_sidebar()\n",
        "    selected = show_custom_pages(selected)  # ãƒ›ãƒ¼ãƒ ãªã© custom_ui å´\n",
        "\n",
        "    page_table: Dict[str, Callable[[], None]] = {\n",
        "        \"åŸºæœ¬è¦ç´ \": render_basic,\n",
        "        \"ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ\": render_layout,\n",
        "        \"å…¥åŠ›è¦ç´ \": render_inputs,\n",
        "    }\n",
        "\n",
        "    if selected in page_table:\n",
        "        page_table[selected]()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RssTcD_IELSN"
      },
      "source": [
        "ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-E7ucR6ELSN",
        "outputId": "9621cd0b-919d-4d0d-92f0-6d4d50332606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "å…¬é–‹URL: https://f89e-34-125-210-255.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.210.255:8501\u001b[0m\n",
            "\u001b[0m\n",
            "/content/lecture-ai-engineering/day1/01_streamlit_UI/app.py:84: UserWarning: Glyph 12469 (\\N{KATAKANA LETTER SA}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(buf, format=\"png\")\n",
            "/content/lecture-ai-engineering/day1/01_streamlit_UI/app.py:84: UserWarning: Glyph 12452 (\\N{KATAKANA LETTER I}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(buf, format=\"png\")\n",
            "/content/lecture-ai-engineering/day1/01_streamlit_UI/app.py:84: UserWarning: Glyph 12531 (\\N{KATAKANA LETTER N}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(buf, format=\"png\")\n",
            "/content/lecture-ai-engineering/day1/01_streamlit_UI/app.py:84: UserWarning: Glyph 27874 (\\N{CJK UNIFIED IDEOGRAPH-6CE2}) missing from font(s) DejaVu Sans.\n",
            "  fig.savefig(buf, format=\"png\")\n",
            "2025-04-21 05:45:37.838 The `use_column_width` parameter has been deprecated and will be removed in a future release. Please utilize the `use_container_width` parameter instead.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"å…¬é–‹URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbYyXVFjELSN"
      },
      "source": [
        "å…¬é–‹URLã®å¾Œã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹URLã«ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã¨ã€streamlitã®UIãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚\n",
        "\n",
        "app.pyã®ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã•ã‚Œã¦ã„ã‚‹ç®‡æ‰€ã‚’ç·¨é›†ã™ã‚‹ã“ã¨ã§ã€UIãŒã©ã®æ§˜ã«å¤‰åŒ–ã™ã‚‹ã‹ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n",
        "\n",
        "streamlitã®å…¬å¼ãƒšãƒ¼ã‚¸ã«ã¯ã€ã‚®ãƒ£ãƒ©ãƒªãƒ¼ãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "\n",
        "streamlitã‚’ä½¿ã†ã¨pythonã¨ã„ã†ä¸€ã¤ã®è¨€èªã§ã‚ã£ã¦ã‚‚ã€æ§˜ã€…ãªUIã‚’å®Ÿç¾ã§ãã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚\n",
        "\n",
        "https://streamlit.io/gallery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmtP5GLOELSN"
      },
      "source": [
        "å¾Œç‰‡ä»˜ã‘ã¨ã—ã¦ã€ä½¿ã†å¿…è¦ã®ãªã„ngrokã®ãƒˆãƒ³ãƒãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "8Ek9QgahELSO"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-T8tFpyELSO"
      },
      "source": [
        "# 02_streamlit_app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqogFQKnELSO"
      },
      "source": [
        "\n",
        "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€Œ02_streamlit_appã€ã«ç§»å‹•ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeEjlJ7uELSO",
        "outputId": "5aa30922-ceef-4b57-eb8a-2379a0cf0e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/lecture-ai-engineering/day1/02_streamlit_app\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/02_streamlit_app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XUH2AstELSO"
      },
      "source": [
        "å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "mDqvI4V3ELSO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO31umGZELSO"
      },
      "source": [
        "ngrokã¨huggigfaceã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€èªè¨¼ã‚’è¡Œã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPxTiEWQELSO",
        "outputId": "b5099379-14d1-4b42-d6cd-208898c564d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "The token `AIE_2` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `AIE_2`\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz4WrELLELSP"
      },
      "source": [
        "stramlitã§Huggingfaceã®ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ã‚’æ‰±ã†ãŸã‚ã«ã€streamlitç”¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.streamlitï¼‰ã‚’ä½œæˆã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ã®æƒ…å ±ã‚’æ ¼ç´ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "W184-a7qFP0W"
      },
      "outputs": [],
      "source": [
        "# .streamlit/secrets.toml ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ\n",
        "import os\n",
        "import toml\n",
        "\n",
        "# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºä¿\n",
        "os.makedirs('.streamlit', exist_ok=True)\n",
        "\n",
        "# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€\n",
        "secrets = {\n",
        "    \"huggingface\": {\n",
        "        \"token\": os.environ.get(\"HUGGINGFACE_TOKEN\", \"\")\n",
        "    }\n",
        "}\n",
        "\n",
        "# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã‚€\n",
        "with open('.streamlit/secrets.toml', 'w') as f:\n",
        "    toml.dump(secrets, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK0vI_xKELSP"
      },
      "source": [
        "ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¾ã™ã€‚\n",
        "\n",
        "02_streamlit_appã§ã¯ã€Huggingfaceã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã€åˆå›èµ·å‹•ã«ã¯2åˆ†ç¨‹åº¦æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚\n",
        "\n",
        "ã“ã®å¾…ã¡æ™‚é–“ã‚’åˆ©ç”¨ã—ã¦ã€app.pyã®ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewbmHUlVEvy8"
      },
      "source": [
        "**config.py ã®æ›¸ãæ›ãˆ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLhul3GQE0Bu",
        "outputId": "63b2e244-9072-40e7-8ebb-df823336ba20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile config.py\n",
        "# ãƒ¢ãƒ‡ãƒ«è¨­å®š\n",
        "DATABASE_FILE = \"chat_history.db\"\n",
        "MODEL_NAME = \"meta-llama/Llama-3-8B-Japanese\"\n",
        "\n",
        "# UIè¨­å®š\n",
        "MAX_HISTORY_ITEMS = 10\n",
        "THEME_COLOR = \"#FF4B4B\"\n",
        "ENABLE_DARK_MODE = True\n",
        "ENABLE_CACHING = True  # è¿½åŠ ï¼šã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æ©Ÿèƒ½ã®æœ‰åŠ¹åŒ–\n",
        "STREAM_OUTPUT = False  # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ã‚’ç„¡åŠ¹åŒ–\n",
        "\n",
        "# è©•ä¾¡æŒ‡æ¨™è¨­å®š\n",
        "METRICS = [\n",
        "    \"bleu_score\",\n",
        "    \"cosine_similarity\",\n",
        "    \"sentiment_score\",\n",
        "    \"response_time\",\n",
        "    \"token_generation_speed\",\n",
        "    \"perplexity\"\n",
        "]\n",
        "\n",
        "# è¿½åŠ æ©Ÿèƒ½è¨­å®š\n",
        "ENABLE_CHAT_EXPORT = True\n",
        "ENABLE_ERROR_LOGGING = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhaRy8Bt6f4h"
      },
      "source": [
        "**metrics.py ã®æ›¸ãæ›ãˆ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBCnjqZ26ktb",
        "outputId": "74cc3d51-f1ec-4ce5-8a9e-496f679f4fe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting metrics.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile metrics.py\n",
        "import time\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "import math\n",
        "import re\n",
        "\n",
        "# å¿…è¦ãªNLTKãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "try:\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    print(\"NLTK loaded successfully.\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "class MetricsCalculator:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "\n",
        "    def calculate_bleu_score(self, reference, candidate):\n",
        "        \"\"\"BLEUã‚¹ã‚³ã‚¢ã‚’è¨ˆç®— (0-1, é«˜ã„ã»ã©è‰¯ã„)\"\"\"\n",
        "        reference_tokens = nltk.word_tokenize(reference.lower())\n",
        "        candidate_tokens = nltk.word_tokenize(candidate.lower())\n",
        "        return sentence_bleu([reference_tokens], candidate_tokens)\n",
        "\n",
        "    def calculate_cosine_similarity(self, text1, text2):\n",
        "        \"\"\"ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®— (0-1, é«˜ã„ã»ã©ä¼¼ã¦ã„ã‚‹)\"\"\"\n",
        "        try:\n",
        "            tfidf_matrix = self.vectorizer.fit_transform([text1, text2])\n",
        "            return cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    def calculate_sentiment_score(self, text):\n",
        "        \"\"\"æ„Ÿæƒ…åˆ†æã‚¹ã‚³ã‚¢ã‚’è¨ˆç®— (-1: éå¸¸ã«ãƒã‚¬ãƒ†ã‚£ãƒ–, 1: éå¸¸ã«ãƒã‚¸ãƒ†ã‚£ãƒ–)\"\"\"\n",
        "        sentiment = TextBlob(text).sentiment.polarity\n",
        "        return sentiment\n",
        "\n",
        "    def calculate_sentiment_metrics(self, text):\n",
        "        \"\"\"è©³ç´°ãªæ„Ÿæƒ…åˆ†æãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—\"\"\"\n",
        "        sentiment = TextBlob(text).sentiment\n",
        "\n",
        "        return {\n",
        "            \"polarity\": sentiment.polarity,  # -1.0 to 1.0\n",
        "            \"subjectivity\": sentiment.subjectivity,  # 0.0 to 1.0\n",
        "            \"vader_compound\": sentiment.polarity,\n",
        "            \"vader_negative\": max(0, -sentiment.polarity),\n",
        "            \"vader_neutral\": 1.0 - abs(sentiment.polarity),\n",
        "            \"vader_positive\": max(0, sentiment.polarity)\n",
        "        }\n",
        "\n",
        "    def calculate_perplexity(self, text, n=3):\n",
        "        \"\"\"å˜ç´”ãªN-gramãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ããƒ†ã‚­ã‚¹ãƒˆã®è¤‡é›‘ã•æ¨å®šï¼ˆä½ã„ã»ã©è‡ªç„¶ï¼‰\"\"\"\n",
        "        tokens = nltk.word_tokenize(text.lower())\n",
        "        if len(tokens) < n:\n",
        "            return float('inf')  # ãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã™ãã‚‹å ´åˆ\n",
        "\n",
        "        # N-gramã‚«ã‚¦ãƒ³ãƒˆ\n",
        "        ngrams = {}\n",
        "        for i in range(len(tokens) - n + 1):\n",
        "            gram = ' '.join(tokens[i:i+n-1])\n",
        "            next_token = tokens[i+n-1]\n",
        "\n",
        "            if gram not in ngrams:\n",
        "                ngrams[gram] = {}\n",
        "\n",
        "            if next_token not in ngrams[gram]:\n",
        "                ngrams[gram][next_token] = 0\n",
        "\n",
        "            ngrams[gram][next_token] += 1\n",
        "\n",
        "        # ãƒ‘ãƒ¼ãƒ—ãƒ¬ã‚­ã‚·ãƒ†ã‚£è¨ˆç®—\n",
        "        log_prob = 0.0\n",
        "        for i in range(len(tokens) - n + 1):\n",
        "            gram = ' '.join(tokens[i:i+n-1])\n",
        "            next_token = tokens[i+n-1]\n",
        "\n",
        "            if gram in ngrams and next_token in ngrams[gram]:\n",
        "                total = sum(ngrams[gram].values())\n",
        "                prob = ngrams[gram][next_token] / total\n",
        "                log_prob += math.log2(prob)\n",
        "            else:\n",
        "                log_prob += math.log2(1e-10)  # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°\n",
        "\n",
        "        perplexity = 2 ** (-log_prob / (len(tokens) - n + 1))\n",
        "        return perplexity\n",
        "\n",
        "    def calculate_response_time(self, start_time):\n",
        "        \"\"\"å¿œç­”æ™‚é–“ã‚’è¨ˆç®—ï¼ˆç§’å˜ä½ï¼‰\"\"\"\n",
        "        return time.time() - start_time\n",
        "\n",
        "    def calculate_token_generation_speed(self, text, generation_time):\n",
        "        \"\"\"ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆé€Ÿåº¦ã‚’è¨ˆç®—ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³/ç§’ï¼‰\"\"\"\n",
        "        if generation_time <= 0:\n",
        "            return 0\n",
        "        # ç°¡æ˜“çš„ãªãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¨å®šï¼ˆå®Ÿéš›ã«ã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ç•°ãªã‚‹ï¼‰\n",
        "        token_count = len(re.findall(r'\\w+|[^\\w\\s]', text))\n",
        "        return token_count / generation_time\n",
        "\n",
        "    def calculate_all_metrics(self, reference, candidate, generation_time):\n",
        "        \"\"\"ã™ã¹ã¦ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—\"\"\"\n",
        "        metrics = {\n",
        "            \"bleu_score\": self.calculate_bleu_score(reference, candidate),\n",
        "            \"cosine_similarity\": self.calculate_cosine_similarity(reference, candidate),\n",
        "            \"sentiment\": self.calculate_sentiment_metrics(candidate),\n",
        "            \"response_time\": generation_time,\n",
        "            \"token_generation_speed\": self.calculate_token_generation_speed(candidate, generation_time),\n",
        "            \"perplexity\": self.calculate_perplexity(candidate)\n",
        "        }\n",
        "        return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJahIGtm6crr"
      },
      "source": [
        "**llm.pyã®æ›¸ãæ›ãˆ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APfi3UtA6HcZ",
        "outputId": "c5b9a581-f5b8-4385-b35c-1b8ab7e17121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting llm.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile llm.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "import time\n",
        "from config import MODEL_NAME, STREAM_OUTPUT, ENABLE_CACHING\n",
        "\n",
        "class LLMGenerator:\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.load_model()\n",
        "\n",
        "    @st.cache_resource\n",
        "    def load_model_cached(_self):\n",
        "        \"\"\"ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹\"\"\"\n",
        "        print(f\"ãƒ¢ãƒ‡ãƒ« {MODEL_NAME} ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
        "\n",
        "        # é‡å­åŒ–è¨­å®š\n",
        "        quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_compute_dtype=torch.float16\n",
        "        )\n",
        "\n",
        "        # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "        # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆ4bité‡å­åŒ–ï¼‰\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            MODEL_NAME,\n",
        "            quantization_config=quantization_config,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.float16\n",
        "        )\n",
        "\n",
        "        return model, tokenizer\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å‡¦ç†ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ãªå ´åˆã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ï¼‰\"\"\"\n",
        "        if ENABLE_CACHING:\n",
        "            self.model, self.tokenizer = self.load_model_cached()\n",
        "        else:\n",
        "            print(f\"ãƒ¢ãƒ‡ãƒ« {MODEL_NAME} ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
        "\n",
        "            # é‡å­åŒ–è¨­å®š\n",
        "            quantization_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_compute_dtype=torch.float16\n",
        "            )\n",
        "\n",
        "            # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "            # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆ4bité‡å­åŒ–ï¼‰\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                MODEL_NAME,\n",
        "                quantization_config=quantization_config,\n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.float16\n",
        "            )\n",
        "\n",
        "    def generate_text(self, prompt, max_length=512, temperature=0.7, stream_handler=None):\n",
        "        \"\"\"ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ\n",
        "            if \"meta-llama\" in MODEL_NAME.lower():\n",
        "                formatted_prompt = f\"<human>: {prompt}\\n<assistant>: \"\n",
        "            else:\n",
        "                formatted_prompt = f\"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {prompt}\\nã‚·ã‚¹ãƒ†ãƒ : \"\n",
        "\n",
        "            # å…¥åŠ›ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰\n",
        "            inputs = self.tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "            generation_args = {\n",
        "                \"max_new_tokens\": max_length,\n",
        "                \"temperature\": temperature,\n",
        "                \"top_p\": 0.95,\n",
        "                \"top_k\": 50,\n",
        "                \"repetition_penalty\": 1.1,\n",
        "                \"do_sample\": temperature > 0.1,\n",
        "                \"pad_token_id\": self.tokenizer.eos_token_id\n",
        "            }\n",
        "\n",
        "            # ç”Ÿæˆ\n",
        "            output = self.model.generate(\n",
        "                **inputs,\n",
        "                **generation_args\n",
        "            )\n",
        "\n",
        "            # å‡ºåŠ›ã®ãƒ‡ã‚³ãƒ¼ãƒ‰\n",
        "            generated_text = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéƒ¨åˆ†ã‚’å‰Šé™¤\n",
        "            generated_text = generated_text.replace(formatted_prompt, \"\")\n",
        "\n",
        "            generation_time = time.time() - start_time\n",
        "            return generated_text, generation_time\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
        "            generation_time = time.time() - start_time\n",
        "            return f\"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\", generation_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1IJsTLP6v2K"
      },
      "source": [
        "**custom_ui.py è¿½åŠ **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-soh1H-60kk",
        "outputId": "d10a34b2-3fd3-4663-e3fe-7d43197bbe69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting custom_ui.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile custom_ui.py\n",
        "import streamlit as st\n",
        "from streamlit_option_menu import option_menu\n",
        "\n",
        "def create_sidebar():\n",
        "    \"\"\"ã‚«ã‚¹ã‚¿ãƒ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’ä½œæˆã™ã‚‹é–¢æ•°\"\"\"\n",
        "    with st.sidebar:\n",
        "        selected = option_menu(\n",
        "            \"ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼\",\n",
        "            [\"ãƒ›ãƒ¼ãƒ \", \"åŸºæœ¬è¦ç´ \", \"ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ\", \"å…¥åŠ›è¦ç´ \", \"ãƒ†ãƒ¼ãƒè¨­å®š\"],\n",
        "            icons=[\"house\", \"list-task\", \"columns\", \"input-cursor\", \"palette\"],\n",
        "            menu_icon=\"cast\",\n",
        "            default_index=0,\n",
        "        )\n",
        "\n",
        "        # ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰/ãƒ©ã‚¤ãƒˆãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆ\n",
        "        if \"light_mode\" not in st.session_state:\n",
        "            st.session_state.light_mode = True\n",
        "\n",
        "        if st.button(\"ğŸŒ“ ãƒ†ãƒ¼ãƒåˆ‡æ›¿\"):\n",
        "            st.session_state.light_mode = not st.session_state.light_mode\n",
        "\n",
        "        # ã‚«ã‚¹ã‚¿ãƒ CSS\n",
        "        if not st.session_state.light_mode:\n",
        "            st.markdown(\"\"\"\n",
        "            <style>\n",
        "            .main {background-color: #0E1117; color: white;}\n",
        "            .sidebar .sidebar-content {background-color: #262730; color: white;}\n",
        "            </style>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        return selected\n",
        "\n",
        "def page_hourglass():\n",
        "    \"\"\"ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ãƒ‡ãƒ¢ãƒšãƒ¼ã‚¸\"\"\"\n",
        "    import time\n",
        "\n",
        "    st.subheader(\"æ”¹å–„ã•ã‚ŒãŸãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º\")\n",
        "    progress_text = \"å‡¦ç†ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...\"\n",
        "    my_bar = st.progress(0, text=progress_text)\n",
        "    placeholder = st.empty()\n",
        "\n",
        "    for percent_complete in range(100):\n",
        "        time.sleep(0.02)\n",
        "        my_bar.progress(percent_complete + 1, text=f\"{progress_text} ({percent_complete+1}%)\")\n",
        "        if percent_complete % 10 == 0:\n",
        "            placeholder.info(f\"Step {percent_complete // 10 + 1}/10 å®Œäº†\")\n",
        "\n",
        "    my_bar.empty()\n",
        "    placeholder.empty()\n",
        "    st.success(\"å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
        "\n",
        "def show_custom_pages(selected):\n",
        "    \"\"\"é¸æŠã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã«åŸºã¥ã„ã¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¡¨ç¤º\"\"\"\n",
        "    if selected == \"ãƒ›ãƒ¼ãƒ \":\n",
        "        st.title(\"Streamlit UIãƒ‡ãƒ¢ï¼ˆæ”¹å–„ç‰ˆï¼‰\")\n",
        "        st.write(\"\"\"ã“ã®ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒªã¯ã€Streamlitã®åŸºæœ¬çš„ãªUIè¦ç´ ã‚’ç´¹ä»‹ã™ã‚‹ã‚‚ã®ã§ã™ã€‚\n",
        "        ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ç•°ãªã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠã—ã¦ã€æ§˜ã€…ãªStreamlitã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚\"\"\")\n",
        "\n",
        "        # ã‚«ãƒ¼ãƒ‰è¦ç´ ã®è¿½åŠ \n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.info(\"**åŸºæœ¬è¦ç´ **\\n\\nãƒ†ã‚­ã‚¹ãƒˆã€ãƒ˜ãƒƒãƒ€ãƒ¼ã€ãƒ¡ãƒ‡ã‚£ã‚¢ãªã©ã®åŸºæœ¬çš„ãªUIè¦ç´ \")\n",
        "        with col2:\n",
        "            st.success(\"**ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ**\\n\\nåˆ—ã€ã‚¿ãƒ–ã€ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ãªã©ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³\")\n",
        "        with col3:\n",
        "            st.warning(\"**å…¥åŠ›è¦ç´ **\\n\\nãƒœã‚¿ãƒ³ã€ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã€ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãªã©ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¦ç´ \")\n",
        "\n",
        "        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ãƒ‡ãƒ¢ã®è¡¨ç¤º\n",
        "        if st.button(\"ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ãƒ‡ãƒ¢ã‚’è¡¨ç¤º\"):\n",
        "            page_hourglass()\n",
        "\n",
        "    # ä»–ã®ãƒšãƒ¼ã‚¸ã®å®Ÿè£…ã¯app.pyã«ä»»ã›ã‚‹\n",
        "    return selected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoRyejCN7IYM"
      },
      "source": [
        "**database.py æ›¸ãæ›ãˆ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-rIp1VF7L1U",
        "outputId": "77becaf3-a102-4a2b-d3eb-04b47f8f2ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting database.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile database.py\n",
        "import sqlite3\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "class ChatDatabase:\n",
        "    def __init__(self, db_file):\n",
        "        self.db_file = db_file\n",
        "        self.initialize_db()\n",
        "\n",
        "    def initialize_db(self):\n",
        "        \"\"\"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®åˆæœŸåŒ–\"\"\"\n",
        "        conn = sqlite3.connect(self.db_file)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«\n",
        "        cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            session_id TEXT,\n",
        "            timestamp TEXT,\n",
        "            user_input TEXT,\n",
        "            model_response TEXT,\n",
        "            response_time REAL,\n",
        "            metrics TEXT\n",
        "        )\n",
        "        ''')\n",
        "\n",
        "        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ†ãƒ¼ãƒ–ãƒ«\n",
        "        cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS feedback (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            chat_id INTEGER,\n",
        "            rating INTEGER,\n",
        "            feedback_text TEXT,\n",
        "            timestamp TEXT,\n",
        "            FOREIGN KEY (chat_id) REFERENCES chat_history (id)\n",
        "        )\n",
        "        ''')\n",
        "\n",
        "        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ–°è¦è¿½åŠ ï¼‰\n",
        "        cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS error_logs (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            timestamp TEXT,\n",
        "            error_type TEXT,\n",
        "            error_message TEXT,\n",
        "            stack_trace TEXT,\n",
        "            input_data TEXT\n",
        "        )\n",
        "        ''')\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def save_chat(self, session_id, user_input, model_response, response_time, metrics=None):\n",
        "        \"\"\"ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ä¿å­˜\"\"\"\n",
        "        conn = sqlite3.connect(self.db_file)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        timestamp = datetime.now().isoformat()\n",
        "        metrics_json = json.dumps(metrics) if metrics else \"{}\"\n",
        "\n",
        "        cursor.execute(\n",
        "            \"INSERT INTO chat_history (session_id, timestamp, user_input, model_response, response_time, metrics) VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "            (session_id, timestamp, user_input, model_response, response_time, metrics_json)\n",
        "        )\n",
        "\n",
        "        chat_id = cursor.lastrowid\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "        return chat_id\n",
        "\n",
        "    def save_feedback(self, chat_id, rating, feedback_text=\"\"):\n",
        "        \"\"\"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä¿å­˜\"\"\"\n",
        "        conn = sqlite3.connect(self.db_file)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        timestamp = datetime.now().isoformat()\n",
        "\n",
        "        cursor.execute(\n",
        "            \"INSERT INTO feedback (chat_id, rating, feedback_text, timestamp) VALUES (?, ?, ?, ?)\",\n",
        "            (chat_id, rating, feedback_text, timestamp)\n",
        "        )\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def get_chat_history(self, session_id=None, limit=10, offset=0):\n",
        "        \"\"\"ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å–å¾—\"\"\"\n",
        "        conn = sqlite3.connect(self.db_file)\n",
        "        conn.row_factory = sqlite3.Row\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        if session_id:\n",
        "            cursor.execute(\n",
        "                \"SELECT * FROM chat_history WHERE session_id = ? ORDER BY timestamp DESC LIMIT ? OFFSET ?\",\n",
        "                (session_id, limit, offset)\n",
        "            )\n",
        "        else:\n",
        "            cursor.execute(\n",
        "                \"SELECT * FROM chat_history ORDER BY timestamp DESC LIMIT ? OFFSET ?\",\n",
        "                (limit, offset)\n",
        "            )\n",
        "\n",
        "        rows = cursor.fetchall()\n",
        "        history = []\n",
        "\n",
        "        for row in rows:\n",
        "            feedback_cursor = conn.cursor()\n",
        "            feedback_cursor.execute(\n",
        "                \"SELECT rating, feedback_text FROM feedback WHERE chat_id = ?\",\n",
        "                (row['id'],)\n",
        "            )\n",
        "            feedback = feedback_cursor.fetchone()\n",
        "\n",
        "            chat_item = dict(row)\n",
        "            if feedback:\n",
        "                chat_item['feedback_rating'] = feedback['rating']\n",
        "                chat_item['feedback_text'] = feedback['feedback_text']\n",
        "            else:\n",
        "                chat_item['feedback_rating'] = None\n",
        "                chat_item['feedback_text'] = None\n",
        "\n",
        "            try:\n",
        "                chat_item['metrics'] = json.loads(chat_item['metrics'])\n",
        "            except:\n",
        "                chat_item['metrics'] = {}\n",
        "\n",
        "            history.append(chat_item)\n",
        "\n",
        "        conn.close()\n",
        "        return history\n",
        "\n",
        "    def get_total_chat_count(self, session_id=None):\n",
        "        \"\"\"ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ç·æ•°ã‚’å–å¾—\"\"\"\n",
        "        conn = sqlite3.connect(self.db_file)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        if session_id:\n",
        "            cursor.execute(\n",
        "                \"SELECT COUNT(*) FROM chat_history WHERE session_id = ?\",\n",
        "                (session_id,)\n",
        "            )\n",
        "        else:\n",
        "            cursor.execute(\"SELECT COUNT(*) FROM chat_history\")\n",
        "\n",
        "        count = cursor.fetchone()[0]\n",
        "        conn.close()\n",
        "        return count\n",
        "\n",
        "    def log_error(self, error_type, error_message, stack_trace=\"\", input_data=\"\"):\n",
        "        \"\"\"ã‚¨ãƒ©ãƒ¼ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ï¼ˆæ–°è¦è¿½åŠ ï¼‰\"\"\"\n",
        "        conn = sqlite3.connect(self.db_file)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        timestamp = datetime.now().isoformat()\n",
        "\n",
        "        cursor.execute(\n",
        "            \"INSERT INTO error_logs (timestamp, error_type, error_message, stack_trace, input_data) VALUES (?, ?, ?, ?, ?)\",\n",
        "            (timestamp, error_type, error_message, stack_trace, input_data)\n",
        "        )\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def get_statistics(self):\n",
        "        \"\"\"ãƒãƒ£ãƒƒãƒˆçµ±è¨ˆæƒ…å ±ã‚’å–å¾—ï¼ˆæ–°è¦è¿½åŠ ï¼‰\"\"\"\n",
        "        conn = sqlite3.connect(self.db_file)\n",
        "        conn.row_factory = sqlite3.Row\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # å¹³å‡å¿œç­”æ™‚é–“\n",
        "        cursor.execute(\"SELECT AVG(response_time) as avg_response_time FROM chat_history\")\n",
        "        avg_response_time = cursor.fetchone()['avg_response_time'] or 0\n",
        "\n",
        "        # ç·ãƒãƒ£ãƒƒãƒˆæ•°\n",
        "        cursor.execute(\"SELECT COUNT(*) as total_chats FROM chat_history\")\n",
        "        total_chats = cursor.fetchone()['total_chats'] or 0\n",
        "\n",
        "        # å¹³å‡è©•ä¾¡\n",
        "        cursor.execute(\"SELECT AVG(rating) as avg_rating FROM feedback\")\n",
        "        avg_rating = cursor.fetchone()['avg_rating'] or 0\n",
        "\n",
        "        # è©•ä¾¡åˆ†å¸ƒ\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT rating, COUNT(*) as count\n",
        "            FROM feedback\n",
        "            GROUP BY rating\n",
        "            ORDER BY rating\n",
        "        \"\"\")\n",
        "        rating_distribution = {row['rating']: row['count'] for row in cursor.fetchall()}\n",
        "\n",
        "        conn.close()\n",
        "\n",
        "        return {\n",
        "            'avg_response_time': avg_response_time,\n",
        "            'total_chats': total_chats,\n",
        "            'avg_rating': avg_rating,\n",
        "            'rating_distribution': rating_distribution\n",
        "        }\n",
        "\n",
        "# ä½¿ç”¨ä¾‹\n",
        "if __name__ == \"__main__\":\n",
        "    db = ChatDatabase(\"test.db\")\n",
        "    chat_id = db.save_chat(\"test_session\", \"ã“ã‚“ã«ã¡ã¯\", \"ã“ã‚“ã«ã¡ã¯ï¼\", 0.5, {\"bleu_score\": 0.8})\n",
        "    db.save_feedback(chat_id, 5, \"ã¨ã¦ã‚‚è‰¯ã„å¿œç­”ã§ã—ãŸ\")\n",
        "    history = db.get_chat_history(\"test_session\")\n",
        "    print(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1hK7yN07WwB"
      },
      "source": [
        "**app.py æ›¸ãæ›ãˆ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vh7DCt87ac7",
        "outputId": "c138fdde-a71c-4c2c-ba62-dbf520657c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import uuid\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# ãƒšãƒ¼ã‚¸è¨­å®š\n",
        "st.set_page_config(\n",
        "    page_title=\"æ”¹å–„ç‰ˆãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª\",\n",
        "    page_icon=\"ğŸ¤–\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\",\n",
        ")\n",
        "\n",
        "# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–\n",
        "if 'session_id' not in st.session_state:\n",
        "    st.session_state.session_id = str(uuid.uuid4())\n",
        "if 'chat_history' not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "\n",
        "# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½œæˆ\n",
        "with st.sidebar:\n",
        "    st.title(\"æ”¹å–„ç‰ˆãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª\")\n",
        "\n",
        "    # ãƒ†ãƒ¼ãƒè¨­å®š\n",
        "    theme = st.selectbox(\n",
        "        \"ãƒ†ãƒ¼ãƒ\",\n",
        "        [\"ãƒ©ã‚¤ãƒˆ\", \"ãƒ€ãƒ¼ã‚¯\", \"ãƒ–ãƒ«ãƒ¼\", \"ã‚°ãƒªãƒ¼ãƒ³\"]\n",
        "    )\n",
        "\n",
        "    # ãƒ†ãƒ¼ãƒã«åŸºã¥ã„ã¦ã‚«ã‚¹ã‚¿ãƒ CSSã‚’é©ç”¨\n",
        "    if theme == \"ãƒ€ãƒ¼ã‚¯\":\n",
        "        st.markdown(\"\"\"\n",
        "        <style>\n",
        "        .main {background-color: #0E1117; color: white;}\n",
        "        .stButton button {background-color: #4CAF50; color: white;}\n",
        "        </style>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "    elif theme == \"ãƒ–ãƒ«ãƒ¼\":\n",
        "        st.markdown(\"\"\"\n",
        "        <style>\n",
        "        .main {background-color: #E8F4F8;}\n",
        "        .stButton button {background-color: #0078D7; color: white;}\n",
        "        </style>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "    elif theme == \"ã‚°ãƒªãƒ¼ãƒ³\":\n",
        "        st.markdown(\"\"\"\n",
        "        <style>\n",
        "        .main {background-color: #E8F8E8;}\n",
        "        .stButton button {background-color: #4CAF50; color: white;}\n",
        "        </style>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # ãƒ¡ãƒ‹ãƒ¥ãƒ¼é¸æŠ\n",
        "    page = st.radio(\n",
        "        \"ãƒ¡ãƒ‹ãƒ¥ãƒ¼\",\n",
        "        [\"ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ\", \"ğŸ“š å±¥æ­´\", \"ğŸ“Š åˆ†æ\"]\n",
        "    )\n",
        "\n",
        "    if page == \"ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ\":\n",
        "        st.subheader(\"è¨­å®š\")\n",
        "\n",
        "        # å¿œç­”ã‚¹ã‚¿ã‚¤ãƒ«\n",
        "        response_style = st.select_slider(\n",
        "            \"å¿œç­”ã‚¹ã‚¿ã‚¤ãƒ«\",\n",
        "            options=[\"ç°¡æ½”\", \"æ¨™æº–\", \"è©³ç´°\"],\n",
        "            value=\"æ¨™æº–\"\n",
        "        )\n",
        "\n",
        "        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒªã‚»ãƒƒãƒˆ\n",
        "        if st.button(\"æ–°ã—ã„ä¼šè©±ã‚’é–‹å§‹\"):\n",
        "            st.session_state.chat_history = []\n",
        "            st.session_state.session_id = str(uuid.uuid4())\n",
        "            st.success(\"æ–°ã—ã„ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã—ãŸ\")\n",
        "\n",
        "# ãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸\n",
        "if page == \"ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ\":\n",
        "    st.title(\"ãƒãƒ£ãƒƒãƒˆ\")\n",
        "\n",
        "    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º\n",
        "    for chat in st.session_state.chat_history:\n",
        "        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.write(chat[\"user_input\"])\n",
        "\n",
        "        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            st.write(chat[\"model_response\"])\n",
        "\n",
        "            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¡¨ç¤ºï¼ˆæŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ï¼‰\n",
        "            if \"metrics\" in chat:\n",
        "                with st.expander(\"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™\"):\n",
        "                    metrics = chat[\"metrics\"]\n",
        "\n",
        "                    # åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹\n",
        "                    cols = st.columns(3)\n",
        "                    with cols[0]:\n",
        "                        st.metric(\"å¿œç­”æ™‚é–“\", f\"{metrics['response_time']:.2f}ç§’\")\n",
        "                    with cols[1]:\n",
        "                        st.metric(\"æ–‡å­—æ•°\", f\"{len(chat['model_response'])}\")\n",
        "                    with cols[2]:\n",
        "                        st.metric(\"ç”Ÿæˆé€Ÿåº¦\", f\"{len(chat['model_response']) / metrics['response_time']:.1f} æ–‡å­—/ç§’\")\n",
        "\n",
        "            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯\n",
        "            if not chat.get(\"feedback_rating\"):\n",
        "                col1, col2, col3, col4, col5 = st.columns(5)\n",
        "                with col3:\n",
        "                    st.write(\"ã“ã®å›ç­”ã¯ã„ã‹ãŒã§ã—ãŸã‹ï¼Ÿ\")\n",
        "\n",
        "                col1, col2, col3 = st.columns(3)\n",
        "                with col1:\n",
        "                    if st.button(\"ğŸ‘ æ‚ªã„\", key=f\"bad_{chat['id']}\"):\n",
        "                        chat[\"feedback_rating\"] = 1\n",
        "                        st.experimental_rerun()\n",
        "                with col2:\n",
        "                    if st.button(\"ğŸ‘ æ™®é€š\", key=f\"fair_{chat['id']}\"):\n",
        "                        chat[\"feedback_rating\"] = 3\n",
        "                        st.experimental_rerun()\n",
        "                with col3:\n",
        "                    if st.button(\"ğŸ‘ğŸ‘ è‰¯ã„\", key=f\"good_{chat['id']}\"):\n",
        "                        chat[\"feedback_rating\"] = 5\n",
        "                        st.experimental_rerun()\n",
        "            else:\n",
        "                st.success(f\"è©•ä¾¡: {'ğŸ‘' * (chat['feedback_rating'] // 2)}\")\n",
        "\n",
        "    # æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å…¥åŠ›\n",
        "    user_input = st.chat_input(\"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„\")\n",
        "\n",
        "    if user_input:\n",
        "        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.write(user_input)\n",
        "\n",
        "        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            message_placeholder = st.empty()\n",
        "\n",
        "            # å¿œç­”ç”Ÿæˆï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰\n",
        "            start_time = time.time()\n",
        "            with st.spinner(\"è€ƒãˆä¸­...\"):\n",
        "                # å¿œç­”ã‚¹ã‚¿ã‚¤ãƒ«ã«åŸºã¥ã„ã¦ç•°ãªã‚‹å¿œç­”ã‚’ç”Ÿæˆ\n",
        "                if response_style == \"ç°¡æ½”\":\n",
        "                    time.sleep(0.5)\n",
        "                    response = f\"è³ªå•ã€Œ{user_input}ã€ã¸ã®ç°¡æ½”ãªå›ç­”ã§ã™ã€‚\"\n",
        "                elif response_style == \"è©³ç´°\":\n",
        "                    time.sleep(2.0)\n",
        "                    response = f\"\"\"è³ªå•ã€Œ{user_input}ã€ã¸ã®è©³ç´°ãªå›ç­”ã§ã™ã€‚\n",
        "\n",
        "                    ã“ã“ã§ã¯ã‚‚ã£ã¨è©³ã—ã„èª¬æ˜ã‚’æä¾›ã—ã¾ã™ã€‚å®Ÿéš›ã®LLMã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€ã‚ˆã‚Šé–¢é€£æ€§ã®é«˜ã„æƒ…å ±ãŒç”Ÿæˆã•ã‚Œã¾ã™ã€‚\n",
        "\n",
        "                    è¿½åŠ ã®è©³ç´°æƒ…å ±ã‚„ä¾‹ã‚’å«ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¢ã§ã¯ã€å®Ÿéš›ã®LLMã®ä»£ã‚ã‚Šã«å˜ç´”ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚\"\"\"\n",
        "                else:  # æ¨™æº–\n",
        "                    time.sleep(1.0)\n",
        "                    response = f\"è³ªå•ã€Œ{user_input}ã€ã¸ã®å›ç­”ã§ã™ã€‚å®Ÿéš›ã®LLMã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€ã‚ˆã‚Šé©åˆ‡ãªå›ç­”ãŒç”Ÿæˆã•ã‚Œã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¢ã§ã¯å˜ç´”ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚\"\n",
        "\n",
        "            end_time = time.time()\n",
        "            gen_time = end_time - start_time\n",
        "\n",
        "            message_placeholder.markdown(response)\n",
        "\n",
        "            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—\n",
        "            metrics = {\n",
        "                \"response_time\": gen_time,\n",
        "                \"text_length\": len(response),\n",
        "                \"generation_speed\": len(response) / gen_time\n",
        "            }\n",
        "\n",
        "            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜\n",
        "            chat_id = len(st.session_state.chat_history)\n",
        "            st.session_state.chat_history.append({\n",
        "                \"id\": chat_id,\n",
        "                \"user_input\": user_input,\n",
        "                \"model_response\": response,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"metrics\": metrics\n",
        "            })\n",
        "\n",
        "            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯UI\n",
        "            with st.expander(\"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™\"):\n",
        "                cols = st.columns(3)\n",
        "                with cols[0]:\n",
        "                    st.metric(\"å¿œç­”æ™‚é–“\", f\"{gen_time:.2f}ç§’\")\n",
        "                with cols[1]:\n",
        "                    st.metric(\"æ–‡å­—æ•°\", f\"{len(response)}\")\n",
        "                with cols[2]:\n",
        "                    st.metric(\"ç”Ÿæˆé€Ÿåº¦\", f\"{len(response) / gen_time:.1f} æ–‡å­—/ç§’\")\n",
        "\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                if st.button(\"ğŸ‘ æ‚ªã„\", key=f\"bad_new\"):\n",
        "                    st.session_state.chat_history[-1][\"feedback_rating\"] = 1\n",
        "                    st.experimental_rerun()\n",
        "            with col2:\n",
        "                if st.button(\"ğŸ‘ æ™®é€š\", key=f\"fair_new\"):\n",
        "                    st.session_state.chat_history[-1][\"feedback_rating\"] = 3\n",
        "                    st.experimental_rerun()\n",
        "            with col3:\n",
        "                if st.button(\"ğŸ‘ğŸ‘ è‰¯ã„\", key=f\"good_new\"):\n",
        "                    st.session_state.chat_history[-1][\"feedback_rating\"] = 5\n",
        "                    st.experimental_rerun()\n",
        "\n",
        "# å±¥æ­´ãƒšãƒ¼ã‚¸\n",
        "elif page == \"ğŸ“š å±¥æ­´\":\n",
        "    st.title(\"ãƒãƒ£ãƒƒãƒˆå±¥æ­´\")\n",
        "\n",
        "    if not st.session_state.chat_history:\n",
        "        st.info(\"å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒãƒ£ãƒƒãƒˆã‚’å§‹ã‚ã¾ã—ã‚‡ã†ï¼\")\n",
        "    else:\n",
        "        # CSV/JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            # CSVãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ\n",
        "            import io\n",
        "            import pandas as pd\n",
        "\n",
        "            csv_data = io.StringIO()\n",
        "            history_df = pd.DataFrame([{\n",
        "                'timestamp': item['timestamp'],\n",
        "                'user_input': item['user_input'],\n",
        "                'model_response': item['model_response'],\n",
        "                'response_time': item['metrics']['response_time'],\n",
        "                'rating': item.get('feedback_rating', 0)\n",
        "            } for item in st.session_state.chat_history])\n",
        "\n",
        "            history_df.to_csv(csv_data, index=False)\n",
        "\n",
        "            st.download_button(\n",
        "                label=\"CSVã¨ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\",\n",
        "                data=csv_data.getvalue(),\n",
        "                file_name=f\"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "                mime=\"text/csv\"\n",
        "            )\n",
        "\n",
        "        with col2:\n",
        "            # JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\n",
        "            json_data = json.dumps([{\n",
        "                'timestamp': item['timestamp'],\n",
        "                'user_input': item['user_input'],\n",
        "                'model_response': item['model_response'],\n",
        "                'metrics': item['metrics'],\n",
        "                'rating': item.get('feedback_rating', 0)\n",
        "            } for item in st.session_state.chat_history], indent=2)\n",
        "\n",
        "            st.download_button(\n",
        "                label=\"JSONã¨ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\",\n",
        "                data=json_data,\n",
        "                file_name=f\"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\",\n",
        "                mime=\"application/json\"\n",
        "            )\n",
        "\n",
        "        # å±¥æ­´è¡¨ç¤º\n",
        "        for i, item in enumerate(st.session_state.chat_history):\n",
        "            with st.expander(f\"{item['timestamp'][:19]} - {item['user_input'][:50]}...\"):\n",
        "                st.subheader(\"ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›\")\n",
        "                st.write(item['user_input'])\n",
        "\n",
        "                st.subheader(\"ãƒ¢ãƒ‡ãƒ«å¿œç­”\")\n",
        "                st.write(item['model_response'])\n",
        "\n",
        "                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º\n",
        "                col1, col2, col3 = st.columns(3)\n",
        "\n",
        "                with col1:\n",
        "                    st.metric(\"å¿œç­”æ™‚é–“\", f\"{item['metrics']['response_time']:.2f}ç§’\")\n",
        "\n",
        "                with col2:\n",
        "                    st.metric(\"æ–‡å­—æ•°\", f\"{len(item['model_response'])}\")\n",
        "\n",
        "                with col3:\n",
        "                    if item.get('feedback_rating'):\n",
        "                        st.metric(\"è©•ä¾¡\", f\"{item['feedback_rating']}/5\")\n",
        "                    else:\n",
        "                        st.info(\"è©•ä¾¡ãªã—\")\n",
        "\n",
        "# åˆ†æãƒšãƒ¼ã‚¸\n",
        "elif page == \"ğŸ“Š åˆ†æ\":\n",
        "    st.title(\"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ\")\n",
        "\n",
        "    if not st.session_state.chat_history:\n",
        "        st.info(\"ã¾ã ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒãƒ£ãƒƒãƒˆã‚’å§‹ã‚ã¦åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¾ã—ã‚‡ã†ï¼\")\n",
        "    else:\n",
        "        # åŸºæœ¬çµ±è¨ˆ\n",
        "        total_chats = len(st.session_state.chat_history)\n",
        "        avg_response_time = sum(chat['metrics']['response_time'] for chat in st.session_state.chat_history) / total_chats\n",
        "        ratings = [chat.get('feedback_rating', 0) for chat in st.session_state.chat_history if chat.get('feedback_rating')]\n",
        "        avg_rating = sum(ratings) / len(ratings) if ratings else 0\n",
        "\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "\n",
        "        with col1:\n",
        "            st.metric(\"ç·ãƒãƒ£ãƒƒãƒˆæ•°\", total_chats)\n",
        "\n",
        "        with col2:\n",
        "            st.metric(\"å¹³å‡å¿œç­”æ™‚é–“\", f\"{avg_response_time:.2f}ç§’\")\n",
        "\n",
        "        with col3:\n",
        "            st.metric(\"å¹³å‡è©•ä¾¡\", f\"{avg_rating:.1f}/5\" if ratings else \"è©•ä¾¡ãªã—\")\n",
        "\n",
        "        # å¿œç­”æ™‚é–“ã®æ¨ç§»\n",
        "        st.subheader(\"å¿œç­”æ™‚é–“ã®æ¨ç§»\")\n",
        "\n",
        "        import pandas as pd\n",
        "        import matplotlib.pyplot as plt\n",
        "\n",
        "        time_data = pd.DataFrame([{\n",
        "            'index': i,\n",
        "            'response_time': chat['metrics']['response_time']\n",
        "        } for i, chat in enumerate(st.session_state.chat_history)])\n",
        "\n",
        "        st.line_chart(time_data.set_index('index')['response_time'])\n",
        "\n",
        "        # è©•ä¾¡åˆ†å¸ƒ\n",
        "        st.subheader(\"è©•ä¾¡åˆ†å¸ƒ\")\n",
        "\n",
        "        from collections import Counter\n",
        "\n",
        "        rating_counts = Counter(ratings)\n",
        "        rating_df = pd.DataFrame({\n",
        "            'è©•ä¾¡': list(rating_counts.keys()),\n",
        "            'å›æ•°': list(rating_counts.values())\n",
        "        })\n",
        "\n",
        "        if not rating_df.empty:\n",
        "            fig, ax = plt.subplots()\n",
        "            ax.bar(rating_df['è©•ä¾¡'], rating_df['å›æ•°'])\n",
        "            ax.set_xlabel('è©•ä¾¡ç‚¹æ•°')\n",
        "            ax.set_ylabel('å›æ•°')\n",
        "            ax.set_xticks(range(1, 6))\n",
        "            ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "            st.pyplot(fig)\n",
        "        else:\n",
        "            st.info(\"ã¾ã è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBQyTTWTELSP",
        "outputId": "a91611cd-3c58-4a1b-e3b3-1c9867ae7f7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "å…¬é–‹URL: https://612c-34-125-210-255.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.210.255:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"å…¬é–‹URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxliKOTawSDe"
      },
      "source": [
        "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æ©Ÿèƒ½ã¨ã—ã¦ã¯ã€ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚„å±¥æ­´é–²è¦§ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "\n",
        "ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã¯ã€Streamlitã«ã‚ˆã‚‹UIéƒ¨åˆ†ã ã‘ã§ã¯ãªãã€SQLiteã‚’ä½¿ç”¨ã—ãŸãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ä¿å­˜ã‚„LLMã®ãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã—ãŸæ¨è«–ãªã©ã®å‡¦ç†ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "- **`app.py`**: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã€‚ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã€å±¥æ­´é–²è¦§ã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã®UIã‚’æä¾›ã—ã¾ã™ã€‚\n",
        "- **`ui.py`**: ãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸ã‚„å±¥æ­´é–²è¦§ãƒšãƒ¼ã‚¸ãªã©ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®UIãƒ­ã‚¸ãƒƒã‚¯ã‚’ç®¡ç†ã—ã¾ã™ã€‚\n",
        "- **`llm.py`**: LLMãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã¨ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’è¡Œã†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚\n",
        "- **`database.py`**: SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä¿å­˜ãƒ»ç®¡ç†ã—ã¾ã™ã€‚\n",
        "- **`metrics.py`**: BLEUã‚¹ã‚³ã‚¢ã‚„ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãªã©ã€å›ç­”ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚\n",
        "- **`data.py`**: ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã‚’è¡Œã†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚\n",
        "- **`config.py`**: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨­å®šï¼ˆãƒ¢ãƒ‡ãƒ«åã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰ã‚’ç®¡ç†ã—ã¾ã™ã€‚\n",
        "- **`requirements.txt`**: ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã«å¿…è¦ãªPythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvm8sWFPELSP"
      },
      "source": [
        "å¾Œç‰‡ä»˜ã‘ã¨ã—ã¦ã€ä½¿ã†å¿…è¦ã®ãªã„ngrokã®ãƒˆãƒ³ãƒãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "WFJC2TmZELSP"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUXhIzV7ELSP"
      },
      "source": [
        "# 03_FastAPI\n",
        "\n",
        "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã€Œ03_FastAPIã€ã«ç§»å‹•ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4ejjDLxr3kfC"
      },
      "outputs": [],
      "source": [
        "# %cd /content/lecture-ai-engineering/day1/03_FastAPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f45TDsNzELSQ"
      },
      "source": [
        "å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uv6glCz5a7Z"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfrmE2VmELSQ"
      },
      "source": [
        "ngrokã¨huggigfaceã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€èªè¨¼ã‚’è¡Œã„ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ELzWhMFORRIO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /Users/yamadayuuhei/Library/Application Support/ngrok/ngrok.yml\n",
            "pyenv: invalid version `/Users/yamadayuuhei/Study/AIE/lecture-ai-engineering/.venv/bin/python' ignored in `/Users/yamadayuuhei/Study/AIE/lecture-ai-engineering/.python-version'\n",
            "pyenv: invalid version `/Users/yamadayuuhei/Study/AIE/lecture-ai-engineering/.venv/bin/python' ignored in `/Users/yamadayuuhei/Study/AIE/lecture-ai-engineering/.python-version'\n",
            "pyenv: huggingface-cli: command not found\n",
            "\n",
            "The `huggingface-cli' command exists in these Python versions:\n",
            "  3.12.4\n",
            "\n",
            "Note: See 'pyenv help global' for tips on allowing both\n",
            "      python2 and python3 to be found.\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-wztc2CELSQ"
      },
      "source": [
        "ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¾ã™ã€‚\n",
        "\n",
        "ã€Œ02_streamlit_appã€ã‹ã‚‰ç¶šã‘ã¦ã€Œ03_FastAPIã€ã‚’å®Ÿè¡Œã—ã¦ã„ã‚‹å ´åˆã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒæ¸ˆã‚“ã§ã„ã‚‹ãŸã‚ã€ã™ãã«ã‚µãƒ¼ãƒ“ã‚¹ãŒç«‹ã¡ä¸ŠãŒã‚Šã¾ã™ã€‚\n",
        "\n",
        "ã€Œ03_FastAPIã€ã®ã¿ã‚’å®Ÿè¡Œã—ã¦ã„ã‚‹å ´åˆã¯ã€åˆå›ã®èµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå§‹ã¾ã‚‹ã®ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒçµ‚ã‚ã‚‹ã¾ã§æ•°åˆ†é–“å¾…ã¡ã¾ã—ã‚‡ã†ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/yamadayuuhei/Study/AIE/lecture-ai-engineering/day1/03_FastAPI\n"
          ]
        }
      ],
      "source": [
        "cd 03_FastAPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting filelock (from transformers)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
            "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Downloading numpy-2.2.5-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0 (from transformers)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Using cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "Collecting requests (from transformers)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
            "Collecting tqdm>=4.27 (from transformers)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
            "  Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "Downloading numpy-2.2.5-cp312-cp312-macosx_14_0_arm64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
            "Using cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
            "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
            "Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m159.6/159.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl (196 kB)\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Installing collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, packaging, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed certifi-2025.4.26 charset-normalizer-3.4.1 filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.30.2 idna-3.10 numpy-2.2.5 packaging-25.0 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.3 typing-extensions-4.13.2 urllib3-2.4.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "meQ4SwISn3IQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/yamadayuuhei/Study/AIE/simplechat/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
            "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/yamadayuuhei/Study/AIE/lecture-ai-engineering/day1/03_FastAPI/app.py\", line 3, in <module>\n",
            "    from transformers import pipeline\n",
            "ModuleNotFoundError: No module named 'transformers'\n"
          ]
        }
      ],
      "source": [
        "!python app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLubjIhbELSR"
      },
      "source": [
        "FastAPIãŒèµ·å‹•ã™ã‚‹ã¨ã€APIã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒé€šä¿¡ã™ã‚‹ãŸã‚ã®URLï¼ˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰ãŒä½œã‚‰ã‚Œã¾ã™ã€‚\n",
        "\n",
        "URLãŒä½œã‚‰ã‚Œã‚‹ã®ã¨åˆã‚ã›ã¦ã€Swagger UIã¨ã„ã†Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãŒä½œã‚‰ã‚Œã¾ã™ã€‚\n",
        "\n",
        "Swagger UIã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ã§ã€APIã®ä»•æ§˜ã‚’ç¢ºèªã§ããŸã‚Šã€APIã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
        "\n",
        "Swagger UIã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€APIã‚’é€šã—ã¦LLMã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgumW3mGELSR"
      },
      "source": [
        "å¾Œç‰‡ä»˜ã‘ã¨ã—ã¦ã€ä½¿ã†å¿…è¦ã®ãªã„ngrokã®ãƒˆãƒ³ãƒãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJymTZio-WPJ"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
